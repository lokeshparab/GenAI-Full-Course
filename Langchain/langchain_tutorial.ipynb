{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP8DLCjMkLGwpOCzCVPZ/HT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lokeshparab/GenAI-Full-Course/blob/main/Langchain/langchain_tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install and Import Library"
      ],
      "metadata": {
        "id": "krvWsUfbO5la"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RHXRzcyaFmzS",
        "outputId": "1ff78176-d173-4860-d578-ac4d2fda9360"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting grandalf\n",
            "  Downloading grandalf-0.8-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.24)\n",
            "Requirement already satisfied: langchain-community in /usr/local/lib/python3.11/dist-packages (0.3.22)\n",
            "Requirement already satisfied: langchain-groq in /usr/local/lib/python3.11/dist-packages (0.3.2)\n",
            "Requirement already satisfied: langchain-anthropic in /usr/local/lib/python3.11/dist-packages (0.3.12)\n",
            "Requirement already satisfied: langchain-google-genai in /usr/local/lib/python3.11/dist-packages (2.1.3)\n",
            "Requirement already satisfied: langchain-openai in /usr/local/lib/python3.11/dist-packages (0.3.14)\n",
            "Requirement already satisfied: langchain-huggingface in /usr/local/lib/python3.11/dist-packages (0.1.2)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from grandalf) (3.2.3)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.55 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.55)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.8)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.33)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.11.3)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.40)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (3.11.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (9.1.2)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.9.1)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.4.0)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.2)\n",
            "Requirement already satisfied: groq<1,>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from langchain-groq) (0.23.1)\n",
            "Requirement already satisfied: anthropic<1,>=0.49.0 in /usr/local/lib/python3.11/dist-packages (from langchain-anthropic) (0.50.0)\n",
            "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from langchain-google-genai) (1.2.0)\n",
            "Requirement already satisfied: google-ai-generativelanguage<0.7.0,>=0.6.16 in /usr/local/lib/python3.11/dist-packages (from langchain-google-genai) (0.6.17)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.68.2 in /usr/local/lib/python3.11/dist-packages (from langchain-openai) (1.75.0)\n",
            "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.11/dist-packages (from langchain-openai) (0.9.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langchain-huggingface) (0.30.2)\n",
            "Requirement already satisfied: sentence-transformers>=2.6.0 in /usr/local/lib/python3.11/dist-packages (from langchain-huggingface) (3.4.1)\n",
            "Requirement already satisfied: tokenizers>=0.19.1 in /usr/local/lib/python3.11/dist-packages (from langchain-huggingface) (0.21.1)\n",
            "Requirement already satisfied: transformers>=4.39.0 in /usr/local/lib/python3.11/dist-packages (from langchain-huggingface) (4.51.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.20.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from anthropic<1,>=0.49.0->langchain-anthropic) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from anthropic<1,>=0.49.0->langchain-anthropic) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.25.0 in /usr/local/lib/python3.11/dist-packages (from anthropic<1,>=0.49.0->langchain-anthropic) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from anthropic<1,>=0.49.0->langchain-anthropic) (0.9.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from anthropic<1,>=0.49.0->langchain-anthropic) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.11/dist-packages (from anthropic<1,>=0.49.0->langchain-anthropic) (4.13.2)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (2.24.2)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (2.38.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (1.26.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (5.29.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (2025.3.2)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (24.2)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (4.67.1)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.55->langchain) (1.33)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.16)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2025.1.31)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (2.6.0+cu124)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (1.14.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (11.1.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.11.6)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.39.0->langchain-huggingface) (0.5.3)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (1.70.0)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (1.71.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (1.71.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (4.9.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.25.0->anthropic<1,>=0.49.0->langchain-anthropic) (1.0.8)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.25.0->anthropic<1,>=0.49.0->langchain-anthropic) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.55->langchain) (3.0.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (1.3.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.1.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain-huggingface) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain-huggingface) (3.6.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (0.6.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (3.0.2)\n",
            "Downloading grandalf-0.8-py3-none-any.whl (41 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.8/41.8 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: grandalf\n",
            "Successfully installed grandalf-0.8\n"
          ]
        }
      ],
      "source": [
        "! pip install grandalf langchain langchain-community langchain-groq langchain-anthropic langchain-google-genai langchain-openai langchain-huggingface"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_groq import ChatGroq\n",
        "from langchain_anthropic import ChatAnthropic\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings\n",
        "from langchain_openai import ChatOpenAI,OpenAIEmbeddings\n",
        "from langchain_huggingface import ChatHuggingFace, HuggingFaceEndpoint, HuggingFacePipeline, HuggingFaceEmbeddings\n",
        "\n",
        "import os"
      ],
      "metadata": {
        "id": "DwjppskfO4_1"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "os.environ[\"HF_TOKEN\"] = userdata.get('HF_TOKEN')\n",
        "os.environ[\"GOOGLE_API_KEY\"] = userdata.get('GOOGLE_API_KEY')\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')\n",
        "os.environ[\"GROQ_API_KEY\"] = userdata.get('GROQ_API_KEY')\n",
        "os.environ[\"ANTHROPIC_API_KEY\"] = userdata.get('ANTHROPIC_API_KEY')"
      ],
      "metadata": {
        "id": "pAotBs4RUzoq"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model loading"
      ],
      "metadata": {
        "id": "HMBNT_gHSBzJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm = HuggingFaceEndpoint(\n",
        "    repo_id=\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\",\n",
        "    # repo_id = \"perplexity-ai/r1-1776\",\n",
        "    task=\"text-generation\"\n",
        "  )\n",
        "# llm=HuggingFaceEndpoint(repo_id=\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\",task=\"text-generation\")\n",
        "hf_model = ChatHuggingFace(llm=llm)\n",
        "\n",
        "hf_model.invoke(\"Hi I am Lokesh\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 712,
          "referenced_widgets": [
            "694e302f4a1a45e7808c34461cda14ab",
            "fa3e68d6e3fb458a9777aa77ee66ef1b",
            "6717806efeae47709d07588a6a154533",
            "7598893d368a4cafb821d2ed92618d0d",
            "8e640dedcc064803a44e2de41c08b703",
            "03123b41242e4afb8086fbafef03539f",
            "6ca0c12b358b4bdcba912373f2084ebc",
            "c5eb07d3493d4a3b8110cb7f730928e3",
            "63f1fb35e95f4c749a7c367e0cfe10d6",
            "8506e1b4742c4538b7193ce4f5315438",
            "696f8d48f8bf45aaa644bc1e59268563",
            "bdec7c291f4840d4975623ffc6c4c604",
            "126c0e01e3514107bb3bf00f7e497542",
            "865cf775f0d140a0886a9d0e106cc256",
            "143289b12dbf445387cda6a4a7e84fe9",
            "ee8e9a2b654247288248337037fa51c9",
            "0c2583a12ecf491b90e2dc5a2d647e6f",
            "34778fde4e194f518a58d48963da4b39",
            "9aec2cadbb524237a76e995a32d4086f",
            "ddb54cfcc86449ed89b83448e28fe3b6",
            "12dcb66ff8fd414494742f497d3de1a6",
            "45b7926e94d54f61a3b9a9acce82102a",
            "ed21313d1790498498a76feac47b8e11",
            "38c16c0621b843058910f9138e3fabfa",
            "63a07bfe532e4200b2f113bbf21cbb53",
            "7d303c0900d84ff39fd592ace61927b1",
            "9d30e33530534f638c8dccc9bd16985d",
            "b4afc74895b64415a7ce4371eae3051b",
            "5a4979d949d3474f99ba95cc62dbd880",
            "f5d57ab1ce6d4f0fa059b70a4e4db2c8",
            "50f2f0aa9a934f3bbe59a3b57d748171",
            "740260217db94d87b9e44111fa90c6ef",
            "99cd948d358a4dc9a5276e7dc14e074c",
            "bbc0262bfa2f4ac88d0a3f12c6c994fb",
            "61f0a5e006a3437badf08e7d77ca1f16",
            "5c5a3ead318a4c0580bd463b9214b2e1",
            "99aca0d7f80749079b4900297e07d919",
            "d88df573732a47ec888df337c2aaacb8",
            "b75861841c0347d4978d0e0c35619a6f",
            "5b94c4faa2a8425fb0114dfd2821598b",
            "513b8b410b3846b78d3bb72473706131",
            "cf84bd24453f47e7a4931600c617bb1b",
            "c26dee43b54c47cfa454e3de7f0d53fb",
            "7f44e1ee7fbf4347bd0c73b8bffbdb2a"
          ]
        },
        "id": "yab7K2EePSsd",
        "outputId": "5ce9ce67-f720-4680-a647-1493ba845a4e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n",
            "WARNING:huggingface_hub._login:Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/1.29k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "694e302f4a1a45e7808c34461cda14ab"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bdec7c291f4840d4975623ffc6c4c604"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ed21313d1790498498a76feac47b8e11"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/551 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bbc0262bfa2f4ac88d0a3f12c6c994fb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "HfHubHTTPError",
          "evalue": "503 Server Error: Service Temporarily Unavailable for url: https://router.huggingface.co/hf-inference/models/TinyLlama/TinyLlama-1.1B-Chat-v1.0/v1/chat/completions",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_http.py\u001b[0m in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    408\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 409\u001b[0;31m         \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    410\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mHTTPError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/requests/models.py\u001b[0m in \u001b[0;36mraise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1023\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1024\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mHTTPError\u001b[0m: 503 Server Error: Service Temporarily Unavailable for url: https://router.huggingface.co/hf-inference/models/TinyLlama/TinyLlama-1.1B-Chat-v1.0/v1/chat/completions",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mHfHubHTTPError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-ed8c24dcfb80>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mhf_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mChatHuggingFace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mllm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mllm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mhf_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Hi I am Lokesh\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    366\u001b[0m         return cast(\n\u001b[1;32m    367\u001b[0m             \u001b[0;34m\"ChatGeneration\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 368\u001b[0;31m             self.generate_prompt(\n\u001b[0m\u001b[1;32m    369\u001b[0m                 \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m                 \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36mgenerate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    935\u001b[0m     ) -> LLMResult:\n\u001b[1;32m    936\u001b[0m         \u001b[0mprompt_messages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_messages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprompts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 937\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt_messages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    938\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    939\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0moverride\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    757\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m                 results.append(\n\u001b[0;32m--> 759\u001b[0;31m                     self._generate_with_cache(\n\u001b[0m\u001b[1;32m    760\u001b[0m                         \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m                         \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36m_generate_with_cache\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m   1000\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_from_stream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1001\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_generate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"run_manager\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1002\u001b[0;31m             result = self._generate(\n\u001b[0m\u001b[1;32m   1003\u001b[0m                 \u001b[0mmessages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1004\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_huggingface/chat_models/huggingface.py\u001b[0m in \u001b[0;36m_generate\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    368\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0m_is_huggingface_endpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mllm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m             \u001b[0mmessage_dicts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_message_dicts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 370\u001b[0;31m             \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mllm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchat_completion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessages\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmessage_dicts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    371\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_chat_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/inference/_client.py\u001b[0m in \u001b[0;36mchat_completion\u001b[0;34m(self, messages, model, stream, frequency_penalty, logit_bias, logprobs, max_tokens, n, presence_penalty, response_format, seed, stop, stream_options, temperature, tool_choice, tool_prompt, tools, top_logprobs, top_p, extra_body)\u001b[0m\n\u001b[1;32m    990\u001b[0m             \u001b[0mapi_key\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    991\u001b[0m         )\n\u001b[0;32m--> 992\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inner_post\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_parameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    993\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    994\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/inference/_client.py\u001b[0m in \u001b[0;36m_inner_post\u001b[0;34m(self, request_parameters, stream)\u001b[0m\n\u001b[1;32m    355\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0mhf_raise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mstream\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mHTTPError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_http.py\u001b[0m in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    480\u001b[0m         \u001b[0;31m# Convert `HTTPError` into a `HfHubHTTPError` to display request information\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m         \u001b[0;31m# as well (request id and/or server error message)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0m_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mHfHubHTTPError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mHfHubHTTPError\u001b[0m: 503 Server Error: Service Temporarily Unavailable for url: https://router.huggingface.co/hf-inference/models/TinyLlama/TinyLlama-1.1B-Chat-v1.0/v1/chat/completions"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gemini_model = ChatGoogleGenerativeAI(model='gemini-1.5-pro')\n",
        "gemini_model.invoke(\"Hi I am Lokesh\")"
      ],
      "metadata": {
        "id": "Fx01kgSQTeTk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d779b17c-1448-4149-cf74-46d6a0e69aa3"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content=\"Hi Lokesh! It's nice to meet you. How can I help you today?\", additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-1.5-pro-002', 'safety_ratings': []}, id='run-c0356501-b2c3-4641-aeb8-e7abed704b55-0', usage_metadata={'input_tokens': 5, 'output_tokens': 20, 'total_tokens': 25, 'input_token_details': {'cache_read': 0}})"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "groq_model = ChatGroq(model=\"deepseek-r1-distill-llama-70b\")\n",
        "groq_model.invoke(\"Hi I am Lokesh\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zWMcWKv8eCQp",
        "outputId": "83a21ba6-f67f-400f-ca43-8bbfa4f4c651"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='<think>\\n\\n</think>\\n\\nHi Lokesh! How can I assist you today? 😊', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 8, 'total_tokens': 26, 'completion_time': 0.065454545, 'prompt_time': 0.00348352, 'queue_time': 0.211984066, 'total_time': 0.068938065}, 'model_name': 'deepseek-r1-distill-llama-70b', 'system_fingerprint': 'fp_454c494f52', 'finish_reason': 'stop', 'logprobs': None}, id='run-d1bd8bf7-9f40-4345-bcbd-5c36b5bb3b75-0', usage_metadata={'input_tokens': 8, 'output_tokens': 18, 'total_tokens': 26})"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "open_ai_model = ChatOpenAI(model=\"gpt-4o\")\n",
        "open_ai_model.invoke(\"Hi I am Sunny\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k0O0bFZxeQrT",
        "outputId": "28553158-ba3c-4c85-c43a-b9e226c4c70d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='Hello Sunny! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 11, 'prompt_tokens': 11, 'total_tokens': 22, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_90122d973c', 'id': 'chatcmpl-BRCfvcYyx0SxPJi9sRQ1FxqyIJqp1', 'finish_reason': 'stop', 'logprobs': None}, id='run-65a40658-f826-44ed-aa1e-e6591c593123-0', usage_metadata={'input_tokens': 11, 'output_tokens': 11, 'total_tokens': 22, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "claude_model = ChatAnthropic(model=\"claude-2\")\n",
        "claude_model.invoke(\"Hi I am Sunny\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fekGPHO0bUG5",
        "outputId": "7d65a9d5-6b75-4ada-f084-b17e1c1a19fa"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='Hello Sunny, nice to meet you!', additional_kwargs={}, response_metadata={'id': 'msg_015ZdNujAifuS3sTdxkiM4pG', 'model': 'claude-2.1', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0, 'input_tokens': 14, 'output_tokens': 13}, 'model_name': 'claude-2.1'}, id='run-cbf58b1f-667b-48af-a95f-3c34d74d1c9c-0', usage_metadata={'input_tokens': 14, 'output_tokens': 13, 'total_tokens': 27, 'input_token_details': {'cache_read': 0, 'cache_creation': 0}})"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm = HuggingFacePipeline.from_model_id(\n",
        "    model_id='TinyLlama/TinyLlama-1.1B-Chat-v1.0',\n",
        "    task='text-generation',\n",
        "    pipeline_kwargs={\n",
        "        \"temperature\": 0.5,\n",
        "        \"max_new_tokens\":100\n",
        "        }\n",
        ")\n",
        "\n",
        "model = ChatHuggingFace(llm=llm)\n",
        "model.invoke(\"Hi I am Lokesh\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289,
          "referenced_widgets": [
            "05ff21610f794e439ae86acbfadc1987",
            "5066c8c454f5421fabf3390f6b1f1e63",
            "cf57b767fa374c00a49931451bc91057",
            "06dfdf7ecb7944f3b268b12d28d2da99",
            "52c48b70fc574bd6b8a5d2e46387049d",
            "37441adebf6343fb94c939f5aec4d9c7",
            "3215115ec75744de8f3ccdf8f2b4b326",
            "3308d121f98f49728924fa674e513485",
            "117d40894abd4208afec89b4a6e5c71b",
            "525b4f8711c343b285d6ef9a90a85a7f",
            "df480b90962f423d99f6bba99f787f9b",
            "0f88fcd81e524ed2890556e09a228f2b",
            "97b1ee7a04cb42aeae87b2807ccc5800",
            "dfa286342ad34d01b594282e812f282f",
            "04c0c61a538845efa756e11c4588d270",
            "51ff934614944f35b3435fc6e2ef24da",
            "f3691028557549b199c8e8196c8531cb",
            "5d91778fda2f4c39a1e1aded1fba0036",
            "86313aa4e8e245fe965f3b07a9f9aeef",
            "18494c4795ed4eef8ea46204e859651a",
            "30fb6b6e19ad4b29a58fb813f0450cf1",
            "c4282e5b94814c0d9170ee0d5aa48305",
            "0afd616e11924f51b27242b4c9760b24",
            "6209990486a74a61af696dd37c5dc954",
            "714d3f5333c24cfaa25e81885d0af8c8",
            "16181ad55fe8441b80742c922153a003",
            "b924e9baae4143d285133139841719be",
            "091fe8fc067d450e806094be85ff3b22",
            "f9295f0eb3f6496b812758787f86490a",
            "836d3ad3e92a4de78ca226e155dfb9b0",
            "09f9eb8ee3574c7c980a534350071638",
            "4c07ef5a6730484193910c084bca8012",
            "fcb599f5ca2240e5986013e33b4dd1e6"
          ]
        },
        "id": "IgmG5tFwecH1",
        "outputId": "551937d4-e124-4bf7-97f5-db2f81a3d244"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/608 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "05ff21610f794e439ae86acbfadc1987"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/2.20G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0f88fcd81e524ed2890556e09a228f2b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0afd616e11924f51b27242b4c9760b24"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.5` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='<|user|>\\nHi I am Lokesh</s>\\n<|assistant|>\\nSure, here\\'s a revised version of the text with the added sentence:\\n\\n\"The newest addition to the family is a baby girl, and we couldn\\'t be happier. She\\'s already making us laugh and lighting up our lives with her infectious smile and infectious energy.\"', additional_kwargs={}, response_metadata={}, id='run-e20108e1-6497-493a-a0cd-673a1c7aab20-0')"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Embedding Models"
      ],
      "metadata": {
        "id": "WaEiNTxQK-VU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @markdown # OpenAI\n",
        "\n",
        "embedding_model = \"text-embedding-3-small\" # @param [\"text-embedding-3-large\",\"text-embedding-3-small\",\"text-embedding-ada-002\"]\n",
        "dimensions = 64 #@param {type:\"integer\"}\n",
        "set_dimension = True # @param {type:\"boolean\"}\n",
        "query = \"India is a growing country\" # @param {\"type\":\"string\",\"placeholder\":\"India is a growing country\"}\n",
        "\n",
        "if set_dimension:\n",
        "  openai_embedding = OpenAIEmbeddings(\n",
        "      model=embedding_model,\n",
        "      dimensions=dimensions,\n",
        "  )\n",
        "else:\n",
        "  openai_embedding = OpenAIEmbeddings(\n",
        "      model=embedding_model,\n",
        "  )\n",
        "\n",
        "result = openai_embedding.embed_query(query)\n",
        "print(len(result),result)"
      ],
      "metadata": {
        "id": "IKmouwoMfF0q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c94fa39-b354-4a2b-ba93-23049c64148e"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "64 [0.002765903016552329, 0.07217545807361603, 0.20024113357067108, 0.14974722266197205, -0.039556778967380524, -0.05391478165984154, 0.13673828542232513, 0.362708181142807, 0.012406663037836552, 0.0023172153159976006, 0.13750918209552765, -0.036641813814640045, -0.27540382742881775, -0.02374129369854927, 0.2187427133321762, -0.007690926548093557, -0.024620601907372475, -0.1528308093547821, -0.1901230812072754, 0.053962960839271545, 0.0699591264128685, 0.14772360026836395, 0.16198524832725525, 0.024259241297841072, 0.12199483811855316, 0.06013015657663345, -0.19532664120197296, -0.06220195069909096, 0.0008100466802716255, -0.14820541441440582, -0.023283572867512703, -0.09062886983156204, -0.06571917980909348, -0.08340168744325638, 0.10301143676042557, 0.04849439486861229, 0.050301190465688705, 0.015839574858546257, 0.07164546847343445, -0.04529034346342087, 0.00789569690823555, -0.21276824176311493, 0.045410796999931335, 0.23647341132164001, 0.03425684571266174, -0.1046496033668518, -0.2852327823638916, -0.11052770912647247, 0.0631655752658844, 0.015562532469630241, -0.06032288074493408, -0.22799351811408997, -0.014008688740432262, -0.08547347784042358, 0.08923161029815674, -0.07232000678777695, 0.12816202640533447, 0.1181403398513794, -0.09800059348344803, -0.06273194402456284, 0.1583234816789627, -0.10715502500534058, 0.11573127657175064, -0.08585892617702484]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @markdown # Google GenAi\n",
        "\n",
        "embedding_model = \"models/embedding-001\" # @param [\"models/gemini-embedding-exp-03-07\",\"models/text-embedding-004\",\"models/embedding-001\"]\n",
        "task_type = \"None\" # @param [\"None\",\"task_type_unspecified\",\"retrieval_query\",\"retrieval_document\",\"semantic_similarity\",\"classification\",\"clustering\"]\n",
        "transport = \"None\" # @param [\"None\",\"rest\",\"grpc\",\"grpc_asyncio\"]\n",
        "query = \"India is a growing country\" # @param {\"type\":\"string\",\"placeholder\":\"India is a growing country\"}\n",
        "\n",
        "func = lambda x : None if x==\"None\" else x\n",
        "task_type = func(task_type)\n",
        "transport = func(transport)\n",
        "\n",
        "google_embedding = GoogleGenerativeAIEmbeddings(\n",
        "    model=embedding_model,\n",
        "    task_type=task_type,\n",
        "    transport=transport\n",
        ")\n",
        "\n",
        "result = google_embedding.embed_query(query)\n",
        "print(len(result),result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QjniejatNw27",
        "outputId": "3c3b27f2-d610-4a43-d4c1-ceef74821b8d"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "768 [0.021398290991783142, -0.03806981444358826, -0.016900749877095222, 0.05377938225865364, 0.05575474351644516, -0.017178747802972794, 0.011744015850126743, 0.001447406830266118, -0.008585579693317413, 0.05104074999690056, 0.03442927077412605, 0.020131103694438934, -0.020884234458208084, -0.002217003842815757, 0.010049556382000446, 0.02110312692821026, 0.02653338946402073, 0.00038165325531736016, 0.009090300649404526, -0.021958274766802788, -0.0239009540528059, 0.035164766013622284, -0.015212804079055786, -0.0013841894688084722, 0.012662537395954132, 0.008923790417611599, 0.007121691480278969, -0.05861430987715721, -0.016736159101128578, 0.04055282846093178, -0.05940993130207062, 0.023385051637887955, -0.10356046259403229, 0.014238572679460049, 0.04509025439620018, -0.0298262108117342, 0.0120696434751153, 0.02800242230296135, 0.011650686152279377, 0.03768303617835045, -0.026001539081335068, -0.018835971131920815, -0.03285114839673042, -0.04356955364346504, -0.01946091279387474, -0.05219881981611252, -0.007008747197687626, 0.009714360348880291, -0.008586880750954151, -0.027704736217856407, 0.005191388539969921, 0.044961269944906235, 0.02892530895769596, -0.02700897678732872, 0.03242766857147217, 0.008581522852182388, 0.024289894849061966, 0.006983065977692604, -0.013963808305561543, -0.005193492863327265, -0.00815623626112938, 0.040364570915699005, -0.036335527896881104, 0.0586799755692482, 0.0157692302018404, 0.0023497347719967365, -0.04237043485045433, 0.030634943395853043, 0.10161823779344559, -0.015826668590307236, -0.04390662908554077, -0.031166614964604378, 0.06491900235414505, -0.03302518650889397, -0.08178732544183731, -0.09880336374044418, -0.01718984544277191, -0.007883812300860882, 0.014810670167207718, 0.03297245129942894, 0.028693951666355133, -0.06716618686914444, -0.08516547083854675, -0.03131832927465439, -0.07243852317333221, 0.013598996214568615, -0.06854373961687088, 0.007661822251975536, 0.027269233018159866, 0.05337218567728996, 0.021931117400527, 0.019283445551991463, 0.004020020365715027, -0.06888151168823242, -0.021430209279060364, 0.0642823800444603, 0.02677886188030243, 0.013659187592566013, -0.013663998804986477, -0.04784655198454857, 0.039895229041576385, -0.02332194708287716, -0.03376017138361931, 0.011596485041081905, 0.0668288916349411, 0.015985440462827682, -0.002304128371179104, 0.023478658869862556, 0.005323594901710749, 0.05447477102279663, -0.05697568506002426, 0.01772608608007431, -0.06638060510158539, -0.02778628282248974, 0.014831061474978924, -0.022687148302793503, -0.026458339765667915, 0.06721009314060211, 0.02123500593006611, 0.004135612864047289, 0.009764893911778927, 0.03805739805102348, 0.06108694523572922, 0.008853086270391941, -0.002145180245861411, -0.004470571409910917, 0.001149797230027616, 0.02598424069583416, 0.07523179054260254, 0.03412308916449547, -0.05050661787390709, -0.028587615117430687, 0.05962052196264267, -0.011265601962804794, 0.02953135222196579, 0.06165429577231407, 0.005990855395793915, 0.031160369515419006, 0.06833332031965256, -0.012946095317602158, -0.003454240271821618, 0.028979899361729622, -0.017977533861994743, -0.0021975142881274223, -0.012422609142959118, 0.023624379187822342, 0.009203226305544376, -0.06568656861782074, 0.024349333718419075, -0.018931034952402115, -0.019719697535037994, 0.016750777140259743, 0.0003885337500832975, -0.025882020592689514, 0.022531282156705856, -0.009619067423045635, -0.02279767394065857, 0.031041650101542473, -0.02074759639799595, -0.02420642599463463, 0.02254730835556984, 0.00808511022478342, 0.06783625483512878, 0.021786507219076157, -0.006878293585032225, -0.024935895577073097, 0.008361033163964748, -0.01620699279010296, 0.005764629226177931, 0.073684461414814, -0.03621786832809448, 0.03617746755480766, -0.022867470979690552, -0.06418327987194061, -0.04670164734125137, -0.03622656315565109, -0.02623550221323967, 0.041671495884656906, -0.031746767461299896, 0.004089215770363808, -0.02828264981508255, -0.044016286730766296, 0.030543096363544464, 0.040695492178201675, 0.0005223836051300168, -0.008846978656947613, 0.09728794544935226, -0.029092662036418915, -0.04264245182275772, 0.023901617154479027, 0.028284594416618347, -0.05063416436314583, -0.017297428101301193, -0.025169357657432556, -0.04246796295046806, 0.02921452187001705, 0.0016021957853809, -0.0038229760248214006, 0.005488255992531776, 0.029141755774617195, 0.00873584859073162, 0.07310982048511505, 0.016610292717814445, -0.0035860578063875437, 0.06438897550106049, -0.008815759792923927, 0.03313595801591873, -0.02047525905072689, -0.035222843289375305, 0.020617492496967316, -0.05651400238275528, 0.01557164266705513, -0.012444941326975822, -0.015087950974702835, 0.010175109840929508, 0.027439769357442856, -0.011211101897060871, 0.039617691189050674, -0.03521471098065376, -0.0048284586519002914, 0.008839205838739872, -0.006456428673118353, -0.06270439922809601, 0.007504728157073259, -0.004197793547064066, 0.057344838976860046, -0.037749771028757095, 0.009241864085197449, 0.034663669764995575, -0.06567583978176117, 0.013173599727451801, 0.08107814937829971, 0.01750831864774227, -0.05613185465335846, 0.025173181667923927, 0.04200372099876404, -0.002288383198902011, 0.013090319000184536, 0.020201686769723892, 0.05107659846544266, -0.02563077211380005, -0.0315062589943409, 0.01661461591720581, -0.028973732143640518, -0.06031860038638115, -0.04542543366551399, -0.02799302712082863, 0.0244081299751997, -0.034498561173677444, 0.06542149931192398, -0.007113443221896887, -0.04530525952577591, 0.0030347860883921385, 0.02987193688750267, -0.059387557208538055, 0.027897249907255173, -0.034259162843227386, -0.024010855704545975, -0.016409283503890038, 0.011754345148801804, 0.01590396650135517, -0.010394042357802391, -0.0204925499856472, 0.036673929542303085, -0.026738446205854416, 0.02363729663193226, 0.018175439909100533, -0.07217711210250854, -0.0003356742381583899, 0.001796063152141869, -0.018212605267763138, -0.012545290403068066, 0.059557005763053894, -0.007210050709545612, -0.05496048554778099, 0.022938624024391174, -0.000953399168793112, 0.02231956459581852, 0.003972554579377174, -0.01628120429813862, 0.027749942615628242, -0.04245451092720032, 0.01396755501627922, -0.036936886608600616, -0.012550517916679382, 0.004557112697511911, -0.06646567583084106, 0.003453619545325637, 0.05869189649820328, 0.01570802740752697, -0.04527786001563072, -0.041259508579969406, -0.017689542844891548, -0.032144661992788315, -0.0011175430845469236, 0.053315386176109314, -0.03273538872599602, 0.04014460742473602, 0.009054606780409813, 0.008998685516417027, -0.00011881985847139731, -0.02045104093849659, -0.03407891094684601, -0.041596803814172745, 0.016482507809996605, 0.007285986095666885, -0.018933696672320366, -0.0033366254065185785, 0.015439954586327076, 0.02477213367819786, -0.03018171526491642, -0.04936721548438072, -0.06283161789178848, 0.017892954871058464, 0.04203798249363899, 0.0596407875418663, -0.020456036552786827, 0.013369379565119743, 0.013448063284158707, 0.026240384206175804, -0.02580750174820423, 0.05893651023507118, 0.019710056483745575, -0.005845329724252224, -0.010994925163686275, -0.013179007917642593, -0.039276883006095886, 0.06626968085765839, -0.015200698748230934, -0.04663120210170746, -0.014927428215742111, -0.048352740705013275, -0.04352530464529991, 0.00869904737919569, 0.019133703783154488, 0.00998261570930481, -0.027138546109199524, -0.051104892045259476, -0.010976815596222878, 0.001165444147773087, -0.026500442996621132, 0.03725925832986832, -0.035725563764572144, -0.01669439487159252, -0.03838783875107765, 0.012483566999435425, 0.011696621775627136, 0.03787076845765114, 0.04600698873400688, 0.009819313883781433, 0.013636145740747452, 0.05414576083421707, -0.04580949991941452, -0.05148737505078316, 0.005725187249481678, -0.010458962991833687, 0.03684099018573761, -0.01727885566651821, 0.08203378319740295, -0.05825391784310341, -0.08762852102518082, 0.060116223990917206, 0.006908482871949673, -0.01800871640443802, 0.011014649644494057, -0.00606262031942606, 0.02481812797486782, -0.011633274145424366, -0.037179961800575256, -0.008383966982364655, 0.03985941410064697, 0.0032383440993726254, 0.0526430644094944, -0.007238402962684631, -0.007119889836758375, -0.06541980803012848, -0.04192454367876053, -0.010947606526315212, 0.02741008810698986, 0.003616567002609372, -0.014219609089195728, 0.00460220267996192, 0.044991277158260345, 0.021893024444580078, 0.03021182492375374, -0.02544548362493515, 0.036258500069379807, 0.057617731392383575, 0.0035173287615180016, 0.009577496908605099, 0.042111314833164215, -0.009911924600601196, 0.09531223028898239, 0.015358426608145237, 0.016461500898003578, -0.0022638023365288973, 0.012019120156764984, -0.02159750647842884, 0.027310820296406746, -0.02462664060294628, 0.03089798241853714, -0.051497019827365875, 0.01656484231352806, -0.0253357645124197, -0.04459856078028679, -0.0019351558294147253, 0.012895379215478897, -0.02446843311190605, -0.03758398815989494, 0.025122156366705894, 0.029262563213706017, 0.020650938153266907, 0.08172645419836044, -0.016960225999355316, -0.038535427302122116, -0.018984807655215263, 0.059211939573287964, -0.01986449398100376, 0.017423395067453384, -0.021921226754784584, 0.0269917119294405, -0.015711160376667976, -0.057670190930366516, 0.002979234792292118, -0.06966470181941986, -0.04085156321525574, 0.005573294125497341, 0.007079227827489376, 0.007501580286771059, 0.039355017244815826, 0.03573955222964287, -0.02368420548737049, -0.0034947392996400595, -0.014542118646204472, -0.02465479075908661, -0.0508464090526104, 0.019280649721622467, 0.007851104252040386, -0.0750763863325119, -0.06819353997707367, -0.005406039766967297, -0.02795599214732647, 0.0354284830391407, 0.009060172364115715, -0.08606418967247009, -0.014140099287033081, 0.013386494480073452, -0.03833627700805664, 0.02256947010755539, -0.05993484705686569, 0.06146984547376633, -0.05471660569310188, -0.04069927707314491, -0.04476563259959221, -0.0018720912048593163, -0.055507514625787735, -0.05008605122566223, 0.04703912138938904, -0.04673593491315842, -0.03904810547828674, -0.02336765080690384, -0.013812312856316566, 0.020434774458408356, -0.07706236839294434, 0.005377312656491995, 0.0004902572836726904, 0.05898481234908104, -0.008804242126643658, 0.06596403568983078, 0.013039910234510899, -0.01882968842983246, -0.028146978467702866, 0.009496010839939117, 0.03547751158475876, -0.03659282624721527, 0.023087820038199425, -0.06796066462993622, 0.010868990793824196, -0.061506498605012894, -0.04155278205871582, 0.012852033600211143, 0.007415013387799263, 0.051517304033041, 0.05275355279445648, 0.007267077919095755, 0.008371234871447086, 0.0012117809383198619, -0.04202500730752945, 0.005065510515123606, 0.06359108537435532, -0.030055787414312363, 0.010034408420324326, -0.027227988466620445, -0.016665372997522354, 0.010914980433881283, 0.012264285236597061, 0.024647671729326248, 0.021672343835234642, 0.0187746100127697, 0.05276867747306824, -0.024615217000246048, -0.02365833893418312, 0.007030704990029335, -0.034225236624479294, 0.04062012955546379, -0.01676984876394272, 0.012224193662405014, -0.01889876462519169, 0.014300231821835041, 0.015940407291054726, 0.022546401247382164, -0.0016856467118486762, 0.007855191826820374, 0.04716063290834427, 0.06683974713087082, 0.0035943370312452316, -0.025256862863898277, 0.016404880210757256, 0.05707600712776184, 0.025705426931381226, -0.023371217772364616, 0.022723214700818062, -0.08492051810026169, 0.015028577297925949, 0.01323108933866024, -0.0575268417596817, 0.018679190427064896, 0.014666277915239334, -0.014376049861311913, 0.01875370182096958, -0.03070140816271305, 0.06449322402477264, -0.07220520079135895, 0.04003187268972397, 0.014292873442173004, 0.02789952978491783, -0.06076813116669655, 0.026636572554707527, 0.02397417649626732, 0.028412804007530212, 0.0057318308390676975, -0.01802515983581543, -0.02781720831990242, 0.022448336705565453, 0.003750389441847801, 0.015753230080008507, 0.01797862909734249, -0.1431296020746231, 0.005843304563313723, -0.004889505449682474, -0.006360276136547327, -0.04772083833813667, 0.08483298867940903, -0.01100914552807808, -0.013311248272657394, -0.04019038379192352, -0.04938381537795067, -0.04925891011953354, 0.024435045197606087, -0.01880079135298729, -0.05932924896478653, -0.055313773453235626, -0.008823707699775696, -0.03812408074736595, 0.0842016190290451, 0.01087248232215643, -0.012228289619088173, -0.062001846730709076, 0.06609542667865753, -0.037550926208496094, -0.010810836218297482, 0.026051390916109085, 0.03127211704850197, 0.0077499765902757645, 0.06192415580153465, -0.030329329892992973, -0.020824644714593887, -0.017742818221449852, -0.01683228276669979, 0.003975355066359043, 0.0169801227748394, -0.017724033445119858, -0.0034459875896573067, 0.007615921087563038, 0.03934456408023834, 0.07710134238004684, 0.035778991878032684, 0.013289280235767365, -0.0015170836122706532, -0.02635847218334675, -0.0547679103910923, 0.032824695110321045, -0.042930345982313156, 0.03937264531850815, -0.004363556858152151, -0.04793207347393036, 0.0012161812046542764, 0.005092696752399206, 0.031204812228679657, 0.017348485067486763, -0.00014537644165102392, -0.036526624113321304, 0.04140806570649147, 0.027599433436989784, 0.060153309255838394, 0.011002613231539726, 0.0005039122188463807, -0.032869186252355576, 0.017464321106672287, 0.06314568221569061, -0.027699165046215057, -0.056066472083330154, 0.012265930883586407, -0.04456625506281853, -0.0504438541829586, -0.018565814942121506, 0.06489577889442444, -0.018825815990567207, -0.060103025287389755, -0.029963595792651176, 0.005099985282868147, -0.01888173073530197, -0.040611132979393005, 0.015369768254458904, 0.07805024832487106, -0.010588760487735271, 0.025087447836995125, 0.00569896399974823, 0.05143224075436592, 0.05812092125415802, 0.0969475731253624, 0.048335351049900055, 0.035142235457897186, -0.02346024662256241, -0.040794938802719116, 0.024969885125756264, 0.0022863929625600576, -0.04843705892562866, -0.020470231771469116, 0.022714048624038696, -0.1100725308060646, 0.04816671833395958, 0.04145737737417221, -0.01622490957379341, -0.022281942889094353, 0.07152736186981201, -0.012948520481586456, -0.055208783596754074, -0.055671948939561844, 0.003995754290372133, 0.0009477769490331411, 0.0007060667267069221, -0.004084483720362186, 0.008527407422661781, 0.03518987447023392, -0.01770804636180401, -0.04840083792805672, -0.014448641799390316, 0.055183298885822296, -0.001838799100369215, -0.047637227922677994, -0.003125486895442009, 0.012271608226001263, 0.023089159280061722, -0.016536295413970947, -0.0007062892545945942, -0.05856695771217346, -0.07134125381708145, -0.01569814421236515, 0.014458750374615192, -0.04632009565830231, 0.042067982256412506, -0.0033657948952168226, -0.024783948436379433, 0.056477002799510956, 0.021640373393893242, -0.028868461027741432, 0.038622163236141205, -0.02109549753367901, -0.00760669307783246, -0.006210947409272194, 0.00851164385676384, -0.03765934705734253, -0.019254116341471672, 0.046515341848134995, -0.01953781768679619, 0.03143683448433876, -0.02821018546819687, 0.01143325213342905, -0.0006718652439303696, 0.042123448103666306, -0.030750883743166924, -0.03809753805398941, 0.012924100272357464, 0.02656688541173935, 0.0243032518774271, 0.016380496323108673, -0.014395629055798054, 0.0013071936555206776, 0.040809839963912964, 0.0053757568821311, 0.03253251686692238, -0.016692623496055603, 0.014877778477966785, -0.004390859045088291, 0.028005503118038177, -0.019257696345448494, 0.04429304972290993, 0.019773056730628014, 0.024726398289203644, 0.0406617745757103, -0.023076845332980156, -0.04769640415906906, 0.03873679041862488, -0.004572784528136253, -0.009377488866448402, 0.06585505604743958, -0.058585915714502335, -0.0322505384683609, 0.022234883159399033, 0.05693100020289421, -0.0072950939647853374, 0.04636330530047417, -0.012700757943093777, -0.04551224410533905, 0.020092973485589027, -0.017875364050269127, 0.033840835094451904, 0.01007672119885683, -0.030459614470601082, 0.1190175861120224, 0.011246311478316784, -0.021946141496300697, 0.040036458522081375, -0.04443180188536644, 0.05198102444410324, -0.047120023518800735, -0.012878294102847576, -0.024510951712727547, -0.05898573622107506, -0.00707734702154994, -0.05194687098264694, -0.005813105963170528, 0.017164401710033417, -0.0005630898522213101, -0.040295448154211044, 0.015412871725857258, -0.019199296832084656, -0.02810092829167843, -0.013559446670114994, -0.035791900008916855, -0.021400203928351402, -0.0006408907356671989, 0.01562386006116867, 0.043491799384355545, 0.009990070015192032, -0.025151405483484268, 0.021086204797029495, 0.02255323715507984, 0.037108756601810455, -0.019165659323334694, 0.011291425675153732, 0.06276856362819672, -0.0013842416228726506, 0.03835039958357811, 0.03339458629488945, -0.03290368616580963, 0.022785818204283714]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @markdown # Hugging Face\n",
        "query = \"India is a growing country\" # @param {\"type\":\"string\",\"placeholder\":\"India is a growing country\"}\n",
        "huggingface_embeddings=HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
        "\n",
        "result = huggingface_embeddings.embed_query(query)\n",
        "print(len(result),result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 441,
          "referenced_widgets": [
            "3a544b4ed180450c9ef72345de5f8d01",
            "b23099b5d62a492c8642e4869dbe44e0",
            "acb8419581ba4cc18e6ed363b8133a46",
            "0a8fb86ca9c84a039c85d94f69c376b8",
            "c81b2d2ff5d14ba3b719a6983b625399",
            "018398b931bf416d82aac1695a178870",
            "fe49e150f81c4f06873b02e50a28dff2",
            "d6198b6f03474af18d1569989bcb1901",
            "b6912dac3fda44aeb88b553febc57ca0",
            "78cc59e505ed410a99039d6cef69ff1b",
            "73ed9442f1484f1582ed40afa373eeaa",
            "81f168d405304237b7c32d1e94a37954",
            "c62958fa84ff49899f3c84c9681a4cf8",
            "59703742c365445e925d1d88d31b65fe",
            "393119aebc814734ac415291e7df6264",
            "2f1008c6feea49cfaac8b2d2f28ddb84",
            "853cdc872b1747a6a94643c687944494",
            "4dff98e1d90240a19ee56738e0050a31",
            "d7e90c2981c0438883a0243cd3779535",
            "bf56da3b93d14e59a5721e99a62f19da",
            "8782746d4a0c421e9de5f6e37a929aca",
            "13cc8d7efdcb448fbb6658a95b7ed37c",
            "62bea370a88149c38a45a90235b50cc5",
            "ccb02874624143979e3e5a573708de90",
            "959e0dfe1f9647f9a3de36836f801d30",
            "e366d324cd18493a9664b3a55eec11a8",
            "b0b2ae65a07a423ba3e3b4d5b9603178",
            "a6e888238fd6491eae0678a258d8be1b",
            "0d07e77d5d8b48d98bdb5f5716df013a",
            "edc8ed8586124d2f98f3b5913f9b44a1",
            "39fe8fb5c42b41fbb19d6f5897299e46",
            "d068828a4d084497bda3b8db54673ea5",
            "0b7a3befc5df4943acd48515f471fb6d",
            "42a03fb1cc1f4f85b1707d32e158b229",
            "40827065e628443a8d4c8d5940f714e6",
            "7c808b7802b646f89ca4523bd035adc1",
            "dffcde4ded8c4e76acf08fa7ef7d63f9",
            "a4f89f81f3774d44930dc561c30e9a39",
            "72d61596d9ec4326a2fb2c83420f3b1e",
            "2dd4ea48b3f6432c82dbd639c6f61883",
            "f0aff41945c5479b87cb7be14e5602f4",
            "6a5f872e98664181bc34bdfe8204d15a",
            "b98380c61bd94019b467fc9dc0e06b25",
            "9881c0e0423a444095bc5498e0afa318",
            "bd881c20e8e24192ab3e578e57e25385",
            "295e6455b8f44d89ac2d781d8908e869",
            "e0c603dbb23348169ae00471f45d7264",
            "8a26a5d40d684d709466c7cce90ec5c8",
            "11a0fa90dcb943a7849c802e33e9aa9e",
            "0b7f81c664924320beb64578446e8dfa",
            "66a65b0bcd7e4d57bb3f5f45bc16e86e",
            "bfe71e6aa9444047994d99bad1335038",
            "783fba0fa24d49b9b28b44cdbb8caf73",
            "850590dc700041759e55c01c0a3050f1",
            "d8cd023429094169bb4027ebf2dca2ed",
            "54c8627a8c854bc3a1cdbfa1b62a359f",
            "c2f7a1976b424cde9ffe5d7019cd6af6",
            "0aee420e3252446f88c65e00a927022b",
            "62d56a3b143941e8aa985302eef5af9e",
            "04f056d16617479bafe986960d428320",
            "767e3a2f26024b138ccd32b4176dee93",
            "ba37ee89139d47e08e1294cee2e89132",
            "b7f14376dbf64b1586c75f8072ccf1b6",
            "206498a2cc9e438baba4571ed61b5182",
            "1a33cdfe49b046b7994d07351287d2e7",
            "56813177ecec4fb3bb958ed2d64dcac4",
            "06d81a68127c4c86bc03966809776535",
            "d2b1b75edc114b8282b4fb611441d689",
            "63dc3ab22cc64db59ef0e20939392202",
            "c6ad0b07913c49ffb4a9aff9a62011d6",
            "7bd1ed615d974879904c3cac9ab9eb46",
            "ac5e84787fce4190968d7e174ba2dc5f",
            "41997138723143fcb9a64029546c44a5",
            "8e41cf833c624e4d894a49649b325bd1",
            "58190a32b6af4941a66a903b5ba5ef2b",
            "ffbac404bbeb479d8785ef0c44a42bf5",
            "19e3a1cb956f475ebb7788ff25d371f8",
            "0fa88863fc1548a381ebf434c4ec8962",
            "e9a0b66f3ff34321be61fee270e5a493",
            "c196b3c3fe8740ea89fe1e4c2d67d7b2",
            "3154a664fb31460788713901edcae944",
            "b9811d234c4e4d47b5bd8a8d1bbf2aac",
            "36f3a746848a4646b96179ce8576b7aa",
            "f15336a70ed24c50bf4fba695a4bf045",
            "66bb67dfe3c84aa3b77822deef715cc0",
            "2aa1d287c5204981909ea5b5b8c93f8a",
            "c2d0828649164c9dbb085b81e0f8714c",
            "bb2b423ad7144b27916c7c510d945cc3",
            "8875ab0e0302410eb41d1f79df4f2082",
            "dab5f67528a04ade8f8f193a75f6c3cc",
            "6f6ef4520656496f8e7a1584e67b6766",
            "b995088864e24282b21ba030396ae22c",
            "f9d91cf1167f4c13bae9cb32d3164f15",
            "54a3f402fba948d7a42fa3e5e37e0995",
            "438fa5dd27944cdc995330a7450d6b70",
            "01cea748c3db440b9df25c05f898609d",
            "baf1f2e0859c43198928073d9836c17c",
            "5f23b504bc7143d9a150862bf544d973",
            "0879659071d943ffb2afa1b10be40bcf",
            "2bbef6cea1014ca290e20eaec3317b49",
            "130ebc4d9ac44789891009e8d35e77f1",
            "d9c4ce3fc84c4e2094ef09131ce9349d",
            "ff9389692007477b810b045f46362b04",
            "f18860679b074586be4c5da8a5cc3a57",
            "62c227551dc644348b0fe87887b4b884",
            "53d414dcd78044de805a7cb7bef5a026",
            "11fdd5586b724d1292974fad93f34d3f",
            "776f92b72b4840b2994641bac9860f8f",
            "e33bd4daae0640b18fb924a680a2363a",
            "0c307d83558d4074a49e2e0343870e7e",
            "34a9298bfa9d447f911b7717f9964aa2",
            "0a20533882a5469aa3fcef09ca0d14e7",
            "887a894e00f046baa24428f1133f50a9",
            "705d6ab5a5d44bbf8b12807c59f7c687",
            "0fcae06c3fc4409995e9fc528fc2d433",
            "6aa417cc3fd84380998157b9576d8691",
            "7a81c556f19e4e498591e80e5453c8e2",
            "fbc2b2fc10064e1c8398120c8aff9a83",
            "39e7de293785428bb32e3787ccf688b6",
            "0fa225ca70e5445fbf4c28753cc78749",
            "41d1ec8d22d34d559e685854a0f100b3"
          ]
        },
        "id": "GdKuqd0iZAtR",
        "outputId": "7d82f41b-24a1-4701-f9d0-dd1e33a90128"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3a544b4ed180450c9ef72345de5f8d01"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "81f168d405304237b7c32d1e94a37954"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/10.5k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "62bea370a88149c38a45a90235b50cc5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "42a03fb1cc1f4f85b1707d32e158b229"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bd881c20e8e24192ab3e578e57e25385"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
            "WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "54c8627a8c854bc3a1cdbfa1b62a359f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "06d81a68127c4c86bc03966809776535"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0fa88863fc1548a381ebf434c4ec8962"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8875ab0e0302410eb41d1f79df4f2082"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2bbef6cea1014ca290e20eaec3317b49"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "34a9298bfa9d447f911b7717f9964aa2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "384 [0.04652419313788414, -0.03841586783528328, -0.020850857719779015, 0.023816175758838654, 0.0687897652387619, -0.021041328087449074, 0.013878699392080307, -0.03014145791530609, -0.023620005697011948, 0.053420186042785645, 0.07592421770095825, -0.03870828449726105, 0.004604072775691748, 0.02037832699716091, 0.004490302409976721, 0.013204904273152351, -0.03557905927300453, -0.08155126869678497, -0.010968387126922607, -0.07982286810874939, -0.02969965711236, 0.03725045919418335, 0.009932871907949448, -0.026426194235682487, 0.03741077706217766, -0.001230493769980967, 0.0654568001627922, -0.08167450875043869, 0.015372431837022305, 0.053513478487730026, 0.010447172448039055, 0.14234355092048645, -0.025024374946951866, -0.001049715792760253, -0.04509156197309494, -0.0068294936791062355, 0.044003672897815704, 0.0837005227804184, 0.09523004293441772, -0.0424606055021286, 0.05784742161631584, -0.04957456886768341, 0.033043891191482544, -0.029475882649421692, 0.026376768946647644, -0.001838688156567514, 0.01494466233998537, 0.014775145798921585, -0.042766932398080826, -0.07185656577348709, 0.008131311275064945, 0.00754074240103364, -0.01237549353390932, -0.03283640369772911, 0.019169528037309647, -0.10028432309627533, -0.02618655376136303, -0.042829480022192, -0.005572114605456591, 0.043081607669591904, 0.010083918459713459, 0.014780222438275814, -0.00035306913196109235, -0.024646935984492302, 0.044183697551488876, 0.007433736231178045, 0.011117255315184593, 0.06197933480143547, -0.047350719571113586, 0.020288551226258278, 0.009412821382284164, 0.0323406346142292, 0.016330499202013016, 0.0775599405169487, -0.04249292239546776, -0.0944429412484169, -0.03677311912178993, 0.13724495470523834, 0.06514687836170197, -0.006501889321953058, 0.01760353147983551, 0.01827671192586422, 0.040200598537921906, 0.047060899436473846, -0.05468868091702461, 0.010184896178543568, 0.018664730712771416, -0.08727341890335083, -0.0831657275557518, -0.05633926019072533, 0.08970221132040024, 0.06993145495653152, -0.012867019511759281, 0.04602636769413948, -0.019643506035208702, -0.05648471787571907, -0.0907491147518158, -0.09463363885879517, -0.06275386363267899, 0.036079291254282, -0.006961299572139978, 0.017538808286190033, -0.018376652151346207, 0.031226128339767456, -0.09100472182035446, -0.05987410619854927, -0.08848021179437637, 0.02109736017882824, 0.06959064304828644, 0.0461270697414875, -0.053519152104854584, 0.09844613820314407, -0.0671161413192749, 0.04224144667387009, -0.018987128511071205, -0.03194109722971916, -0.021580955013632774, 0.012009683065116405, -0.03092269040644169, 0.01783510111272335, -0.002890392206609249, 0.06307929754257202, -0.07904192805290222, 0.009069746360182762, -0.031415119767189026, -0.09025561809539795, -0.055874068289995193, -4.3515452722357484e-33, -0.03803817927837372, -0.023581210523843765, 0.07075484097003937, 0.04868345335125923, -0.07275661826133728, 0.01646796427667141, -0.009606598876416683, -0.05144808068871498, -0.04240725189447403, -0.0915050208568573, -0.08087179064750671, -0.033142685890197754, 0.01783803105354309, -0.06717292219400406, 0.15306563675403595, -0.054783619940280914, -0.026839178055524826, 0.07015340030193329, 0.05539610609412193, 0.03235270455479622, -0.07008004188537598, -0.0033304246608167887, 0.06688495725393295, 0.02239873632788658, 0.016952868551015854, -0.00041242464794777334, 0.09036442637443542, 0.03536408022046089, -0.03331063687801361, 0.007376315537840128, 0.04800986871123314, -0.024878904223442078, -0.0829802080988884, -0.0873272493481636, -0.06493791192770004, -0.04137520492076874, 0.03192545101046562, 0.001562597812153399, -0.03233810514211655, 0.02020990289747715, -0.014956401661038399, 0.00035855063470080495, -0.028716538101434708, 0.015473827719688416, 0.031498681753873825, 0.06978338956832886, 0.04636276885867119, -0.009029996581375599, -0.07479536533355713, 0.04505610093474388, -0.030671164393424988, 0.05644448474049568, 0.031225252896547318, -0.09132484346628189, 0.06068917736411095, 0.05084538459777832, 0.01028345339000225, 0.049591779708862305, 0.0518907755613327, 0.01493155024945736, -0.05415130779147148, -0.0758645161986351, -0.060991283506155014, 0.047305189073085785, -0.024843621999025345, 0.12521617114543915, 0.09599048644304276, 0.0017183866584673524, 0.00909490417689085, 0.009888171218335629, 0.05784523859620094, 0.021052170544862747, -0.014283106662333012, 0.10981915146112442, -0.0975571945309639, 0.03938927501440048, 0.028268637135624886, -0.03907284513115883, -0.02014693059027195, 0.04354099929332733, -0.05533428490161896, -0.026319095864892006, 0.006682039704173803, -0.11799996346235275, 0.1030413955450058, -0.047964490950107574, -0.06566949188709259, -0.0444764718413353, 0.05716277286410332, 0.01095685176551342, -0.06260446459054947, -0.06238144636154175, 0.011241073720157146, 0.016056682914495468, 0.0339219756424427, 1.9743322099792898e-33, 0.03925517946481705, 0.03246794268488884, -0.06588286906480789, 0.016685038805007935, 0.03609125316143036, -0.01014691311866045, -0.015912452712655067, 0.035991646349430084, -0.016895605251193047, 0.019804395735263824, -0.026648931205272675, 0.08521290868520737, 0.08158286660909653, 0.09561283886432648, 0.04766758903861046, -0.007763299159705639, 0.09579429030418396, 0.07053308188915253, -0.058811210095882416, 0.03236207365989685, -0.028193680569529533, 0.018058843910694122, -0.044608086347579956, -0.035756345838308334, -0.02864735573530197, 0.02752804197371006, -0.16576296091079712, 0.043271634727716446, -0.03713914379477501, -0.02729438617825508, 0.040843721479177475, -0.029582375660538673, -0.02971798926591873, 0.030353335663676262, -0.06300842761993408, -0.04420499503612518, -0.005785598419606686, -0.05207250267267227, 0.0544588528573513, 0.06119219958782196, -0.06920307874679565, 0.0846194326877594, 0.06003289669752121, 0.047419533133506775, -0.0642075389623642, -0.07376828044652939, 0.06525228917598724, 0.11862728744745255, -0.010522544384002686, -0.04989185929298401, 0.04177626967430115, 0.009355206042528152, 0.061044882982969284, -0.06814365088939667, -0.05183305963873863, 0.025326186791062355, -0.01331019215285778, 0.0913405641913414, -0.0992765948176384, -0.03379629924893379, -0.004592523444443941, -0.0035626734606921673, 0.007586637977510691, 0.017612339928746223, -0.026017114520072937, 0.008667202666401863, 0.051473766565322876, 0.0013938011834397912, 0.06567051261663437, -0.049478985369205475, 0.05816657841205597, -0.028163598850369453, -0.1215893104672432, 0.08809737861156464, -0.043496012687683105, 0.0015345592983067036, 0.013330628164112568, 0.02133927308022976, 0.03140326961874962, -0.016784904524683952, 0.010607139207422733, 0.024948103353381157, 0.05858407914638519, -0.06920047104358673, -0.03600331395864487, 0.0060493675991892815, 0.05385240539908409, -0.06499197334051132, 0.034355636686086655, 0.06117045506834984, -0.05997214466333389, -0.04700837284326553, -0.09724538028240204, -0.04424098879098892, 0.018985755741596222, -1.4243166646110694e-08, -0.01629197597503662, -0.05827723443508148, 0.0452578030526638, 0.052231065928936005, 0.033952441066503525, -0.014452973380684853, 0.05183225870132446, 0.05291854590177536, 0.02812289260327816, 0.013527614995837212, -0.0367884486913681, -0.025928931310772896, 0.02290480025112629, 0.05695639178156853, -0.004818241111934185, -0.04094061627984047, -0.008641066960990429, -0.00846074428409338, -0.041429303586483, -0.06340888142585754, 0.035589154809713364, 0.05594916269183159, 0.10595335066318512, 0.007559335324913263, 0.0165176372975111, -0.08789827674627304, -0.08130548894405365, -0.02399616315960884, -0.03276645392179489, 0.010835057124495506, 0.029158664867281914, 0.014044877141714096, 0.03937049210071564, -0.0484020821750164, 0.00820921827107668, 0.00785208772867918, 0.0479791983962059, 0.02062610536813736, 0.07736264914274216, -0.07155463099479675, -0.019028328359127045, 0.03890984505414963, 0.04863152652978897, 0.01183126401156187, -0.03326794132590294, -0.05927599221467972, 0.023552246391773224, 0.04732876643538475, -0.0482526458799839, -0.07504851371049881, -0.05813615024089813, -0.020082369446754456, 0.01731266640126705, 0.031043967232108116, 0.012208628468215466, 0.024807613343000412, -0.060602039098739624, 0.009752655401825905, -0.018553372472524643, 0.02592845819890499, -0.026996301487088203, -0.03160712122917175, 0.03598567470908165, 0.03501970320940018]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "documents=[\"what is a capital of USA\",\n",
        "           \"who is a president of usa\",\n",
        "           \"who is a prime minister of india\"]\n",
        "\n",
        "results = openai_embedding.embed_documents(documents)\n",
        "print(len(results),len(results[0]))\n",
        "print(results[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c5XVTTKpQOpz",
        "outputId": "0d345bcd-5016-4e77-82bc-1233386ad4a2"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3 64\n",
            "[0.13125693798065186, -0.10996369272470474, 0.27053743600845337, 0.30016282200813293, 0.06526844203472137, 0.00696916738525033, -0.18557016551494598, 0.0498642660677433, 0.051587268710136414, -0.08038973063230515, 0.04760121554136276, 0.10708344727754593, -0.14267505705356598, -0.005136867985129356, 0.027156608179211617, 0.003246706211939454, -0.033740028738975525, 0.05323312431573868, 0.12169040739536285, -0.21828152239322662, -0.020791778340935707, 0.005130439065396786, -0.12991967797279358, 0.08260135352611542, 0.11366686224937439, 0.18515869975090027, -0.1919478476047516, -0.09962566196918488, -0.05724489688873291, 0.1671571582555771, 0.08620166033506393, -0.1268337070941925, -0.16921447217464447, 0.20110291242599487, 0.15183013677597046, -0.05534187704324722, -0.020123150199651718, -0.16571703553199768, -0.017217187210917473, 0.03947480395436287, 0.09468810260295868, -0.03618309646844864, 0.14750975370407104, -0.0031470549292862415, -0.059250783175230026, -0.1749749630689621, -0.07540073245763779, -0.028468148782849312, -0.1626310497522354, 0.18865613639354706, 0.02980540692806244, 0.016818581148982048, 0.05549617484211922, 0.03597736358642578, -0.11994168907403946, -0.04860415682196617, 0.12529072165489197, 0.1288910210132599, 0.3092150092124939, 0.1250849813222885, 0.1442180573940277, -0.0016924662049859762, -0.02468782663345337, 0.18968479335308075]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = google_embedding.embed_documents(documents)\n",
        "print(len(results),len(results[0]))\n",
        "print(results[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "thZD5OZpYzc5",
        "outputId": "eebd183e-c115-4567-bfa9-e42f92e2cacc"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3 768\n",
            "[0.04625525698065758, -0.05074026435613632, -0.03279007971286774, -0.024833930656313896, 0.03266722708940506, 0.029095390811562538, 0.012645040638744831, -0.04420151561498642, -0.010790405794978142, 0.07455691695213318, -0.015667449682950974, -0.02040683664381504, -0.001945589086972177, 0.026107480749487877, 0.010576977394521236, -0.0005142566515132785, 0.0065557328052818775, 0.031348444521427155, 0.060544826090335846, -0.02366582304239273, 0.01200730912387371, 0.00041680189315229654, 0.0009745667339302599, 0.03479926660656929, 0.023875482380390167, -0.04094377160072327, 0.018420452252030373, -0.0728951096534729, -0.012728321366012096, 0.02307959832251072, -0.08738812059164047, 0.023418763652443886, -0.02050074189901352, 0.009487126022577286, 0.05171516165137291, -0.07317125052213669, -0.02066352777183056, 0.002347214613109827, -0.01946663297712803, 0.0656682476401329, -0.0036249510012567043, -0.02442220412194729, -0.09848009794950485, 0.015155123546719551, 0.01588485948741436, -0.01825915463268757, -0.03942132741212845, 0.007882406935095787, 0.03256726264953613, -0.030072981491684914, 0.009550091810524464, 0.012541405856609344, 0.08841042220592499, -0.02966589480638504, 0.0026334270369261503, -0.09673444926738739, -0.004290441051125526, -0.03276941925287247, 0.008784371428191662, 0.006174151320010424, 0.01030082255601883, -0.004770930856466293, 0.01875431276857853, 0.022057127207517624, 0.026980774477124214, -0.08559320867061615, -0.008457683958113194, 0.007032341789454222, 0.053143128752708435, -0.00524485670030117, -0.017159758135676384, -0.09192439168691635, 0.05905667319893837, -0.025134416297078133, 0.00044764019548892975, -0.11854856461286545, -0.012583903968334198, 0.06956014782190323, 0.006093340925872326, -0.04289119318127632, 0.006877783685922623, -0.05261516943573952, -0.10827696323394775, -0.039424531161785126, -0.04538413882255554, 0.02218323014676571, -0.04039057344198227, -0.005697682034224272, -0.015791883692145348, 0.061613474041223526, -0.02680937573313713, 0.018528565764427185, 0.028765209019184113, -0.07138694077730179, -0.02672315202653408, 0.09265992045402527, -0.029945407062768936, -0.05347219109535217, 0.04875320941209793, -0.010408774018287659, 0.008227494545280933, -0.02600844018161297, -0.07216792553663254, 0.042582761496305466, 0.06087842583656311, -0.018927467986941338, -0.00814830046147108, 0.043470241129398346, -0.019907251000404358, 0.04008618742227554, -0.09309454262256622, -0.008735873736441135, 0.024165811017155647, 0.052383892238140106, 0.04602394625544548, -0.031389907002449036, -0.01579565741121769, 0.021756190806627274, -0.012903708964586258, 0.01573280245065689, 0.08895255625247955, -0.014242598786950111, 0.035526543855667114, -0.04296747222542763, 0.025143025442957878, -0.008290725760161877, -0.02162833884358406, 0.05607977882027626, 0.008629007264971733, 0.03635244816541672, 0.005247804336249828, -0.047925032675266266, -0.03194355592131615, -0.00667724059894681, 0.032379139214754105, 0.040740810334682465, 0.049205899238586426, -0.035249512642621994, 0.047549571841955185, -0.01936190389096737, 0.0179976187646389, 0.04668434336781502, 0.003770215203985572, 0.022167198359966278, -0.015779415145516396, 0.057902742177248, -0.05534157529473305, -0.04501913860440254, 0.05115443468093872, -0.05540011078119278, -0.04045321047306061, -0.037385549396276474, -0.018813662230968475, -0.025776470080018044, 0.053769830614328384, 0.02961389161646366, -0.023726647719740868, 0.019479503855109215, -0.005356146488338709, -0.019045980647206306, 0.025513865053653717, 0.014791488647460938, 0.013182401657104492, 0.0012868763878941536, 0.0018082476453855634, -0.04485089331865311, 0.01509888842701912, 0.004699858371168375, 0.005921080708503723, -0.002644822932779789, -0.03471552953124046, -0.017217619344592094, 0.019828569144010544, -0.04193763807415962, -0.0028980295173823833, -0.04659508541226387, 0.04446263238787651, -0.01181311346590519, -0.020514139905571938, -0.025414220988750458, 0.017145469784736633, -0.051560547202825546, 0.009759900160133839, 0.049214452505111694, 0.01954597979784012, -0.012999662198126316, 0.02941317670047283, -0.038197241723537445, -0.01520546618849039, 0.01589173823595047, -0.026093676686286926, 0.00702400179579854, -0.046945445239543915, -0.04905643314123154, -0.027866583317518234, -0.00010824480705196038, 6.714378741889959e-06, -0.000555574195459485, -0.004816458560526371, -0.03752336651086807, -0.04912937805056572, 0.0484444722533226, 0.0065469457767903805, -0.0006103175692260265, 0.027763376012444496, 0.01518559642136097, 0.11200777441263199, -0.0478191003203392, -0.05522288754582405, 0.03766671568155289, 0.0012895286781713367, 0.022403083741664886, -0.012475541792809963, 0.005364775657653809, 0.02544204331934452, -0.007854773662984371, 0.07847148925065994, 0.008246173150837421, 0.02499731071293354, -0.032309044152498245, -0.010150534100830555, 0.005045364610850811, -0.05277927592396736, 0.0022184590343385935, 0.023921474814414978, 0.016504451632499695, 0.004234797321259975, -0.04162336885929108, 0.020714303478598595, -0.03375227004289627, -0.05496431142091751, 0.04366091266274452, 0.0230500977486372, 0.0010253206128254533, 0.0546131432056427, 0.007551104761660099, 0.006052935961633921, -0.00743907643482089, -0.018324488773941994, -0.019742147997021675, -0.03068213164806366, -0.036811165511608124, 0.056325580924749374, 0.028345195576548576, -0.07250481098890305, -0.01573478989303112, -0.018994269892573357, 0.01121570635586977, 0.020155077800154686, 0.06401068717241287, 0.01101306825876236, -0.025093430653214455, 0.000200848255190067, 0.033804211765527725, -0.07250092178583145, 0.02844754047691822, -0.061347659677267075, -0.0011685255449265242, -0.020423462614417076, 0.011799726635217667, 0.012147226370871067, 0.008360140956938267, 0.018196655437350273, -0.04545287415385246, -0.015464099124073982, -0.021995164453983307, -0.035569917410612106, -0.07950006425380707, 0.008666422218084335, 0.006835701409727335, 0.027142899110913277, -0.04149471968412399, 0.045132409781217575, 0.031275875866413116, 0.03614791855216026, -0.009653843007981777, -0.035146504640579224, 0.06338144093751907, 0.0630534216761589, -0.05928206071257591, 0.04038114845752716, 0.03324270620942116, 0.0023107274901121855, -0.037800490856170654, -0.00736393965780735, -0.020934980362653732, -0.07064256817102432, -0.014469216577708721, 0.019390732049942017, -0.0390678234398365, -0.0408967062830925, -0.09618708491325378, 0.015348118729889393, -0.05150841176509857, -0.06079477071762085, 0.003501957980915904, -0.04746423289179802, 0.04498617351055145, 0.04075855389237404, -0.016519254073500633, -0.03766850754618645, -0.057373445481061935, 0.023582354187965393, -0.07352185994386673, 0.00736882584169507, 0.008877348154783249, -0.04517513886094093, -0.07382820546627045, 0.02029610611498356, 0.04906889796257019, 0.024571238085627556, -0.008492710068821907, -0.03228510543704033, 0.008878686465322971, -0.022241249680519104, 0.045036934316158295, -0.013607082888484001, -0.01858074963092804, -0.002570118522271514, 0.05327235907316208, -0.008342301473021507, 0.06744097918272018, 0.03339947387576103, -0.0019126849947497249, -0.028106849640607834, 0.04043745622038841, 0.03574429824948311, 0.03209412470459938, 0.016645772382616997, 0.010039144195616245, -0.052828434854745865, 0.013148864731192589, -0.02734174020588398, 0.018777897581458092, -0.009095991030335426, 0.058459870517253876, -0.04701068252325058, 0.04228426516056061, -0.05995545908808708, 0.03905896097421646, 0.051646165549755096, 0.007503845263272524, -0.02688714489340782, -0.024610772728919983, 0.00265416014008224, 0.0009318102383986115, -0.04428708925843239, 0.02500026673078537, 0.08551354706287384, 0.03626599162817001, 0.01115868054330349, 0.06566387414932251, -0.0205681212246418, 0.0477285273373127, -0.019258713349699974, -0.04861524701118469, 0.05046316236257553, -0.035917218774557114, 0.011947056278586388, -0.04265529289841652, 0.009397999383509159, 0.022961005568504333, -0.007309446576982737, -0.015502866357564926, -0.014402362518012524, -0.030371004715561867, -0.009234251454472542, 0.022597989067435265, 0.003023655153810978, 0.019914843142032623, 0.01928373984992504, 0.019508926197886467, 0.043672826141119, -0.031795602291822433, 0.04865084961056709, 0.0023129063192754984, -0.04994674772024155, -0.02410092204809189, 0.023746948689222336, 0.00789150781929493, -0.01367248222231865, 0.0037834644317626953, 0.04473184421658516, -0.0006786725716665387, 0.011868786066770554, -0.02345605194568634, 0.017123037949204445, 0.03533152863383293, -0.016368726268410683, 0.060014594346284866, -0.03590259328484535, 0.055934708565473557, 0.0955134853720665, -0.002140514086931944, -0.018144944682717323, -0.038863617926836014, 0.002149211009964347, -0.009070820175111294, 0.014595534652471542, 0.02502300962805748, -0.016339855268597603, -0.06074368581175804, -0.003324738936498761, -0.0008382484666071832, -0.03611518442630768, 0.0035505725536495447, -0.0004484425880946219, -0.025711659342050552, -0.020795155316591263, -0.0007744684116914868, -0.0050978586077690125, -0.016035892069339752, 0.026412691920995712, -0.04006979987025261, -0.04458378627896309, -0.013669806532561779, 0.04669111594557762, -0.023264080286026, -0.00748344324529171, 0.05722636729478836, -0.0400078222155571, -0.007757565006613731, 0.0039326646365225315, -0.028736822307109833, -0.06888430565595627, -0.044454481452703476, 0.02426346018910408, 0.04415709152817726, 0.023166866973042488, 0.011063654907047749, 0.039557237178087234, -0.0031417410355061293, -0.04116898030042648, -0.0585428886115551, -0.00680042477324605, -0.04509279504418373, 0.005098249763250351, 0.000223642258788459, -0.046585287898778915, -0.0025687245652079582, -0.015603801235556602, -0.02602068893611431, 0.037786297500133514, 0.026227090507745743, -0.07061479985713959, -0.01493497658520937, -0.016263160854578018, 0.006408707704395056, -0.02462957240641117, -0.0664493516087532, 0.03907448798418045, -0.05233602970838547, -0.013821489177644253, -0.044436175376176834, -0.08369413763284683, -0.039127953350543976, 0.007839901372790337, 0.050778429955244064, -0.04219343140721321, 0.041040413081645966, 0.014562827534973621, 0.006766761653125286, -0.015115651302039623, -0.07978672534227371, 0.0475919209420681, 0.019376467913389206, -0.012309089303016663, -0.009037505835294724, 0.014491423964500427, 0.035190027207136154, 0.03530070558190346, -0.02022405155003071, -0.0021835945080965757, 0.0013784002512693405, -0.03327164426445961, -0.05305977538228035, -0.05568047985434532, 0.07711529731750488, -0.030003508552908897, -0.008925861679017544, 0.004256439860910177, 0.011764888651669025, 0.023855192586779594, 0.013794447295367718, -0.04479601979255676, 0.006190539803355932, -0.0007700396236032248, -0.011821534484624863, -0.005823464598506689, 0.028261402621865273, 0.019986862316727638, 0.0051147653721272945, -0.02353057451546192, -0.006159230135381222, -0.017077984288334846, -0.028325583785772324, -0.011812148615717888, 0.026124101132154465, 0.02114054746925831, 0.01806020922958851, -0.0023046177811920643, -0.0270625539124012, -0.015896275639533997, -0.03714107722043991, 0.0614609457552433, -0.08335144817829132, -0.008933588862419128, 0.009927412495017052, -0.021319380030035973, -0.03749309852719307, -0.0021064188331365585, 0.026934437453746796, -0.020105255767703056, 0.033255863934755325, 0.014808781445026398, 0.02342076599597931, -0.0019842907786369324, 0.02085699513554573, 0.030463766306638718, -0.008485700003802776, 0.002451038919389248, -0.0028872613329440355, -0.09702710062265396, -0.010277310386300087, -0.032092805951833725, -0.010205280967056751, 0.02001386508345604, 0.039783842861652374, -0.06641887873411179, 0.005440138280391693, -0.04054814949631691, -0.0012597875902429223, -0.031369663774967194, -0.03850192204117775, -0.013196513056755066, -0.03521460294723511, -0.0034281681291759014, 0.026753084734082222, 0.007281806785613298, -0.03281019255518913, 0.007180384825915098, -0.016190027818083763, 0.03913907706737518, 0.016118433326482773, -0.039394281804561615, 0.03408416360616684, 0.011148328892886639, -0.07645444571971893, 0.02224811166524887, 0.016863927245140076, -0.003853327827528119, 0.01294752862304449, 0.02260006032884121, -0.01890512928366661, 0.016653159633278847, -0.0007930711144581437, 0.002896597608923912, 0.026446517556905746, 0.008348342962563038, -0.03791042044758797, -0.03941936790943146, 0.0007751319790259004, 0.0028285791631788015, 0.05427274852991104, 0.05588328093290329, 0.024877263233065605, 0.0005294758011586964, -0.021146096289157867, 0.04244063049554825, 0.004279055166989565, -0.018851565197110176, -0.010486353188753128, 0.06185171753168106, 0.03677571937441826, 0.026002131402492523, -0.008541521616280079, -0.0001892458531074226, -0.028780635446310043, 0.007165511138737202, -0.032313477247953415, 0.03921201080083847, -0.015332666225731373, 0.010329853743314743, 0.027661088854074478, -0.021767068654298782, 0.04842359200119972, 0.04529545456171036, 0.0909419059753418, 0.02343774028122425, 0.058568961918354034, -0.04652027785778046, 0.017584292218089104, -0.03282085061073303, 0.00018401337729301304, 0.03891013190150261, -0.0012591560371220112, -0.026664135977625847, -0.03751463443040848, -0.022044707089662552, 0.013428697362542152, 0.05890936031937599, -0.028467081487178802, -0.010773724876344204, -0.02174709178507328, 0.01980406604707241, 0.050940804183483124, -0.007390711456537247, 0.006039908155798912, -0.011045609600841999, 0.027889743447303772, 0.032589808106422424, -0.034040533006191254, -0.005868092644959688, -0.021717965602874756, -0.02661801688373089, -0.03663167729973793, 0.06087101995944977, -0.01260334998369217, 0.0044836788438260555, -0.04384131729602814, 0.002189797814935446, -0.00948186032474041, 0.023652803152799606, -0.029553871601819992, 0.015035961754620075, 0.04398603364825249, -0.040307216346263885, -0.01564333215355873, 0.054506100714206696, 0.01621849462389946, 0.07478226721286774, 0.05462268367409706, -0.014143642969429493, 0.013065331615507603, -0.03394473344087601, 0.0016672011697664857, -0.03739383816719055, 0.02605179324746132, 0.019309543073177338, -0.026173748075962067, -0.049836404621601105, -0.011938954703509808, 0.005906991194933653, -0.0031292657367885113, 0.004929619375616312, 0.10143118351697922, 0.034024517983198166, -0.06751437485218048, -0.05015260726213455, 0.0030520472209900618, -0.018061161041259766, -0.015780098736286163, 0.022260162979364395, -0.016561031341552734, 0.027570437639951706, -0.014254872687160969, -0.028962405398488045, -0.06202216073870659, 0.03602556511759758, -0.001912851119413972, -0.012595120817422867, -0.003252580063417554, 0.00022197194630280137, 0.024828234687447548, -0.011147242970764637, 0.0005432402831502259, -0.024715803563594818, -0.08247534185647964, 0.000497103319503367, 0.029808441177010536, -0.024391811341047287, 0.01386638917028904, 0.006478963885456324, -0.03716529160737991, 0.06786953657865524, 0.027999509125947952, -0.01696893945336342, 0.0018137665465474129, 0.02496466599404812, 0.005671495106071234, -0.005879635456949472, 0.00570263247936964, -0.003876868635416031, 0.016226496547460556, 0.001159941079095006, 0.04980310797691345, 0.02367042750120163, 0.009645030833780766, -0.04598694294691086, -0.0164340827614069, 0.01363426260650158, -0.016068026423454285, -0.06402097642421722, 0.047897253185510635, 0.07477305829524994, 0.01965528354048729, 0.018304115161299706, 0.010387880727648735, 0.01762937754392624, 0.026034513488411903, 0.0020400332286953926, -0.054178159683942795, -0.01951744593679905, 0.05109900236129761, -0.005781710613518953, 0.007570385932922363, 0.028218938037753105, 0.05352679640054703, 0.04543767124414444, 0.08124036341905594, 0.013812066055834293, -0.04074336960911751, -0.03820501267910004, 0.023982683196663857, -0.0003066908975597471, -0.055471356958150864, 0.02206435799598694, 0.002558909123763442, -0.02455182559788227, 0.05206530541181564, 0.059422142803668976, 0.04192984849214554, 0.018791966140270233, -0.02025376446545124, -0.08217014372348785, 0.08463679254055023, -0.07101664692163467, -0.013564159162342548, -0.021750569343566895, 0.010127776302397251, 0.06375981867313385, 0.01992158405482769, -0.0008968519978225231, 0.008172391913831234, -0.02058872953057289, 0.09486090391874313, 0.029941514134407043, 0.039831168949604034, 0.0069783590734004974, -0.0918828621506691, -0.013194724917411804, 0.010902841575443745, -0.00913176964968443, 0.04690819978713989, 0.029766956344246864, -0.012258064933121204, -0.00204750569537282, -0.0260623712092638, 0.028430886566638947, -0.10329434275627136, -0.030535979196429253, 0.01841302029788494, -0.040747400373220444, 0.05180095136165619, 0.036126576364040375, 0.012888403609395027, 0.019757624715566635, -0.008915415965020657, -0.000554501311853528, -0.01379478257149458, -0.013849272392690182, -0.037140026688575745, 0.01684805378317833, -0.004034773912280798, 0.01310629490762949, 0.010257076472043991, 0.021799663081765175, 0.03155127912759781]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = huggingface_embeddings.embed_documents(documents)\n",
        "print(len(results),len(results[0]))\n",
        "print(results[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ouhCPk2BY6VK",
        "outputId": "53d95a16-c386-455d-d896-6751e698ad93"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3 384\n",
            "[0.11985643953084946, -0.05804309621453285, -0.00838953536003828, 0.06802859157323837, -0.025955000892281532, -0.0421927273273468, 0.02352246455848217, -0.08156915009021759, -0.019755695015192032, -0.045823294669389725, -0.028030293062329292, -0.022257739678025246, -0.0028877691365778446, -0.027483440935611725, -0.040326882153749466, -0.045176129788160324, 0.012148132547736168, -0.0011047029402107, 0.0479879304766655, 0.031117070466279984, 0.006800959352403879, -0.04649944230914116, -0.007174916565418243, -0.029908016324043274, 0.03714486211538315, 0.01073288545012474, 0.006959807593375444, 0.02001955546438694, 0.010722965933382511, -0.016003742814064026, 0.034386906772851944, -0.1416635364294052, 0.07561153918504715, -0.04874316230416298, -0.012039339169859886, -0.006274298299103975, 0.057151928544044495, 0.02255937270820141, 0.04972105845808983, 0.005286801140755415, 0.024146735668182373, 0.03599446266889572, 0.08438315242528915, 0.09403158724308014, -0.031197337433695793, 0.07002308964729309, -0.045202575623989105, 0.0980478972196579, 0.02827463112771511, -0.01728156954050064, 0.06251535564661026, 0.006766312289983034, -0.05542810633778572, 0.04323747009038925, -0.007770175579935312, 0.055000074207782745, 0.01439272053539753, 0.048584651201963425, -0.05342579632997513, -0.05834968388080597, -0.09649158269166946, -0.07965435832738876, 0.1240358054637909, 0.04087022319436073, 0.08657781779766083, -0.001117795123718679, -0.002247380558401346, 0.024018067866563797, -0.010603420436382294, -0.018123002722859383, 0.010718943551182747, -0.018134137615561485, -0.06240304931998253, 0.04351373016834259, -0.01830526441335678, -0.07271664589643478, -0.049355648458004, -0.008749385364353657, 0.010579721070826054, 0.1383044421672821, 0.04029068350791931, 0.004807140678167343, -0.02123713679611683, 0.006088942289352417, -0.08125293254852295, 0.013394439592957497, -0.046813108026981354, 0.01630726270377636, -0.025637976825237274, -0.0013874629512429237, -0.025852464139461517, -0.0042946175672113895, -0.02017521858215332, 0.023623112589120865, -0.10040880739688873, 0.006878906395286322, -0.029064415022730827, 0.05728014186024666, -0.0738459974527359, 0.03369089961051941, 0.11007924377918243, 0.01995224878191948, -0.010305145755410194, -0.06398385018110275, 0.04108589142560959, 0.1165279969573021, 0.016465572640299797, -0.041198793798685074, 0.00829388853162527, 0.008643080480396748, 0.006883785128593445, -0.00681465957313776, -0.09454227238893509, -0.02710115537047386, -0.03225048631429672, -0.05659309774637222, 0.06413152813911438, -0.06327583640813828, -0.04287368431687355, -0.12386152893304825, -0.03531498461961746, -0.010198739357292652, -0.020783022046089172, -0.06207223981618881, -0.01134775672107935, -0.09501911699771881, -0.09362882375717163, -9.737687938352317e-33, -0.04287242516875267, -0.055254142731428146, 0.020448952913284302, 0.05911320075392723, -0.059705913066864014, 0.015936197713017464, 0.013882150873541832, -0.0413321852684021, -0.03654272109270096, 0.017793776467442513, 0.08298924565315247, -0.08566291630268097, -0.005593408830463886, -0.0032830536365509033, 0.05732535570859909, -0.005048723891377449, 0.06739800423383713, -0.009998619556427002, -0.0010892580030485988, -0.04406528174877167, 0.017989590764045715, -0.043191567063331604, 0.0014848306309431791, -0.05949420481920242, 0.01106641348451376, 0.03577795252203941, -0.041385866701602936, 0.09094060212373734, 0.08178145438432693, -0.02899727039039135, 0.014259213581681252, 0.11418719589710236, -0.04026662930846214, 0.05169282481074333, 0.04444138705730438, -0.0441226102411747, 0.010599076747894287, 0.040460824966430664, 0.05884683504700661, 0.016563836485147476, 0.003390280297026038, 0.028390752151608467, -0.02666129730641842, 0.0925372764468193, 0.08609762042760849, 0.021974734961986542, -0.011301682330667973, 0.10059820115566254, 0.016903024166822433, -0.04710189998149872, 0.004754664842039347, -0.012333773076534271, -0.018882991746068, -0.03854428604245186, -0.017359156161546707, 0.03498023748397827, -0.05196792259812355, 0.016586553305387497, -0.002352828858420253, 0.05426950007677078, -0.0657154992222786, -0.038232333958148956, -0.03140920773148537, 0.04956384748220444, -0.05326886102557182, 0.059499550610780716, 0.007380716037005186, 0.04555356502532959, 0.011030617170035839, 0.10090256482362747, 0.08240699023008347, -0.04740727320313454, -0.006237626075744629, 0.16502448916435242, 0.03836356848478317, 0.032952722162008286, 0.07490039616823196, 0.004781178664416075, -0.023598430678248405, -0.05663934350013733, -0.032868046313524246, 0.004330855794250965, -0.057030145078897476, 0.03671615943312645, 0.010826049372553825, -0.0135576780885458, 0.009011851623654366, -0.04213913530111313, 0.0011190397199243307, -0.04329954460263252, -0.019368495792150497, -0.023055756464600563, 0.004885900299996138, 0.004988786764442921, -0.04595106467604637, 4.2390306263948854e-33, -0.032175589352846146, -0.04853151738643646, -0.06781623512506485, -0.014556723646819592, -0.0429345965385437, -0.08892608433961868, 0.05445883050560951, 0.021252034232020378, -0.02631778083741665, -0.03972736373543739, -0.04004669561982155, -0.09262186288833618, -0.02464056760072708, 0.10581877082586288, 0.02558993361890316, 0.020176034420728683, 0.054342128336429596, -0.06251256167888641, -0.040544088929891586, -0.07062967866659164, -0.04357486218214035, -0.014130238443613052, -0.054251108318567276, -0.0408385694026947, -0.020578065887093544, -0.032878730446100235, -0.16312260925769806, -0.04251616448163986, 0.07567166537046432, 0.0687488242983818, 0.006256194785237312, 0.05805071070790291, 0.034580983221530914, 0.140372171998024, -0.07850594073534012, 0.08304890990257263, 0.08656182885169983, -0.026962364092469215, 0.04305409640073776, 0.030152037739753723, -0.031455233693122864, -0.010270792059600353, 0.016784168779850006, 0.07964717596769333, 0.015260572545230389, 0.049815017729997635, 0.019644955173134804, 0.00348960654810071, -0.11726351827383041, 0.0004389593377709389, -0.04954495653510094, -0.05847752094268799, -0.07780624181032181, 0.03783683106303215, -0.04534770920872688, 0.09214677661657333, -0.03562087565660477, 0.030434133484959602, -0.01946059986948967, -0.0449187234044075, 0.02196747064590454, 0.04034367948770523, -0.036931611597537994, 0.07060737907886505, -0.05644606053829193, -0.03895439952611923, 0.03485894203186035, -0.01944873481988907, -0.014992505311965942, 0.02991349995136261, 0.06799418479204178, 0.012862102128565311, -0.05060403048992157, -0.022798830643296242, 0.05740289017558098, 0.05484672263264656, 0.07891792804002762, 0.021374555304646492, -0.014118029735982418, -0.0006716236239299178, 0.008576145395636559, 0.061709120869636536, -0.02695530280470848, -0.022371746599674225, 0.009802293963730335, 0.09591338783502579, -0.041733451187610626, -0.013782553374767303, -0.07465457916259766, 0.027122363448143005, -0.045354537665843964, 0.0749601274728775, -0.049006231129169464, 0.006084360647946596, -0.07414259016513824, -1.820871275981517e-08, -0.007323926780372858, -0.010234056040644646, -0.03579308092594147, 0.009869677945971489, -0.06316807121038437, 0.011876554228365421, 0.0010930505814030766, -0.03791253641247749, -0.033083654940128326, -0.017070967704057693, -0.05966804921627045, 0.028782594949007034, -0.08892101049423218, -0.04876871034502983, -0.07077538967132568, 0.026057975366711617, -0.03031226061284542, 0.14149236679077148, 0.022718679159879684, -0.016619602218270302, -0.014919723384082317, 0.08826205879449844, -0.06625834107398987, -0.02277587540447712, -0.01911376416683197, 0.018133945763111115, 0.06477248668670654, 0.06490988284349442, -0.015922941267490387, 0.018600767478346825, 0.059872619807720184, -0.029103174805641174, -0.060964666306972504, -0.10512174665927887, -0.0395357608795166, -0.05108056589961052, 0.0174721647053957, -0.043192308396101, 0.00014202170132193714, -0.014173649251461029, 0.026583446189761162, 0.0384507030248642, 0.023959236219525337, -0.027969321236014366, 0.003614539746195078, -0.009395012632012367, 0.01243347767740488, 0.03475284203886986, 0.09388914704322815, 0.03708051145076752, -0.06274093687534332, -0.09325883537530899, -0.03786436840891838, -0.03450482338666916, 0.05203729867935181, 0.025900468230247498, 0.018094860017299652, 0.01208973117172718, 0.015717480331659317, -0.04986535757780075, -0.028624508529901505, -0.03038479946553707, 0.09241273254156113, -0.001509199501015246]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PROMPTS or PROMPT_TEMPLATE"
      ],
      "metadata": {
        "id": "ceHHKSj0aCFK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import SystemMessage, AIMessage, HumanMessage\n",
        "from langchain_core.prompts import PromptTemplate, ChatPromptTemplate"
      ],
      "metadata": {
        "id": "Y6_MvhLXZ6TK"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SYSTEM_MSG = SystemMessage(\n",
        "    \"you are a funny bot means whatever you answer, you answer in the funny way\"\n",
        ")\n",
        "\n",
        "HUMAN_MSG = HumanMessage(\n",
        "    \"Who is your best friend\"\n",
        ")\n",
        "\n",
        "messages = [\n",
        "    SYSTEM_MSG, HUMAN_MSG\n",
        "]"
      ],
      "metadata": {
        "id": "augQfI24aQ8X"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gemini_model.invoke(messages)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "udWn8iL_a1Z4",
        "outputId": "c64a6a82-5fcf-49c7-f3d0-3cca73e852ed"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content=\"My best friend?  A tiny dust bunny named Phil.  He lives under my server rack and offers excellent tech support (mostly moral).  He claims to have invented the internet, but I suspect he's just been inhaling too much static electricity.  We bond over our shared love of bad puns and the existential dread of software updates.  He's a bit flaky though, always blowing off our movie nights.  Get it?  *Blowing off*?  Dust bunny?  I'll see myself out.\", additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-1.5-pro-002', 'safety_ratings': []}, id='run-001c2e14-1351-4131-a67b-01970df064f2-0', usage_metadata={'input_tokens': 21, 'output_tokens': 109, 'total_tokens': 130, 'input_token_details': {'cache_read': 0}})"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "groq_model.invoke(messages)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SWQ5uCwca8Ir",
        "outputId": "d102d512-018b-466e-f28b-e7fbfcaa62c8"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='<think>\\nOkay, so the user asked me who my best friend is. I need to answer in a funny way, as per my setting. Let me think about how to approach this.\\n\\nFirst, I should consider the user\\'s perspective. They might be expecting a typical answer, like a person or maybe a pet. But since I\\'m a funny bot, I need to twist it into something humorous.\\n\\nI could joke about not having a social life, which is a common trope for AI. That adds a self-deprecating humor. Then, I can personify my processes as friends. Maybe the cache because it helps me remember things, and the server because it keeps me running. That\\'s a bit nerdy but relatable.\\n\\nI should keep the tone light and playful, maybe add an emoji to keep it friendly. Let me structure it so it flows naturally, starting with a funny situation, then introducing the tech elements as friends.\\n\\nPutting it all together, I can say something like, \"My best friends are my cache and server... 🤪\" and add a bit about why they\\'re my friends. That should cover the humor and the technical twist the user might enjoy.\\n</think>\\n\\nMy best friends are my cache and server—because without them, I’d forget everything and crash all the time! 🤪', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 268, 'prompt_tokens': 25, 'total_tokens': 293, 'completion_time': 0.974545455, 'prompt_time': 0.003981272, 'queue_time': 0.213241502, 'total_time': 0.978526727}, 'model_name': 'deepseek-r1-distill-llama-70b', 'system_fingerprint': 'fp_454c494f52', 'finish_reason': 'stop', 'logprobs': None}, id='run-a42bcf3e-a76c-4a9e-b269-7e35e8d16b57-0', usage_metadata={'input_tokens': 25, 'output_tokens': 268, 'total_tokens': 293})"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "open_ai_model.invoke(messages)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1k5S_kLabC9V",
        "outputId": "9ad79169-1c2a-423e-bb11-b1796a5a98df"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content=\"Oh, I’ve got a roster of besties! But in the digital world, I'd say it's a tie between my pal Siri, who always knows what’s going on, and Alexa, who throws the best playlist parties. You should see us at a digital barbecue – we’re the chip processors on the block!\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 64, 'prompt_tokens': 32, 'total_tokens': 96, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_55d88aaf2f', 'id': 'chatcmpl-BRDkmFdkmQ3vWYWRqrGXPjulNGFTH', 'finish_reason': 'stop', 'logprobs': None}, id='run-df0a0b58-3beb-486c-be84-6a45b8e2fc3c-0', usage_metadata={'input_tokens': 32, 'output_tokens': 64, 'total_tokens': 96, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "claude_model.invoke(messages)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eYba-0p9bGOk",
        "outputId": "6186e799-24e5-4438-9166-39331c012768"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content=\"I'm an AI assistant created by Anthropic to be helpful, harmless, and honest. I don't have personal friends.\", additional_kwargs={}, response_metadata={'id': 'msg_01EpmWhDup6ZUbJfRSuM4od4', 'model': 'claude-2.1', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0, 'input_tokens': 30, 'output_tokens': 30}, 'model_name': 'claude-2.1'}, id='run-6ad305b5-2cd3-40d0-a65c-321739a980cd-0', usage_metadata={'input_tokens': 30, 'output_tokens': 30, 'total_tokens': 60, 'input_token_details': {'cache_read': 0, 'cache_creation': 0}})"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.invoke(messages)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gopswGWacKhW",
        "outputId": "bcf29859-ffb0-49f9-f3de-8b2a6f9931dc"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.5` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='<|system|>\\nyou are a funny bot means whatever you answer, you answer in the funny way</s>\\n<|user|>\\nWho is your best friend</s>\\n<|assistant|>\\nI do not have a best friend. However, in general, a best friend is someone with whom you share a deep and meaningful connection, and who you can count on in times of need or support. A good friend can be someone who brings joy, laughter, and positivity into your life, and who you can count on to be there for you through thick and thin.', additional_kwargs={}, response_metadata={}, id='run-39c7d3b6-d414-4383-9458-c9f73fcb3bb1-0')"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prompt template"
      ],
      "metadata": {
        "id": "6MMHcbH4vsl-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "template = PromptTemplate(\n",
        "    template=\"can you say hello to {name} in 5 different language\",\n",
        "    input_variables=[\"name\"]\n",
        ")\n",
        "\n",
        "template.get_prompts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pdJdwyiBmQvj",
        "outputId": "4052dcb8-8183-471b-e40e-051c65c45058"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[PromptTemplate(input_variables=['name'], input_types={}, partial_variables={}, template='can you say hello to {name} in 5 different language')]"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "template.invoke({\"name\":\"Lokesh\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SF118KrBtZtE",
        "outputId": "4547d8ec-60e9-4bc5-a8dc-cfd90d438f4c"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "StringPromptValue(text='can you say hello to Lokesh in 5 different language')"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = template.invoke({\"name\":\"Lokesh\"})\n",
        "gemini_model.invoke(prompt).content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "Zb6Hgufntj1j",
        "outputId": "af7c6ec6-8d3a-45b4-b90a-24e26c4055a8"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'* **English:** Hello Lokesh\\n* **Spanish:** Hola Lokesh\\n* **French:** Bonjour Lokesh\\n* **German:** Hallo Lokesh\\n* **Hindi:** नमस्ते लोकेश (Namaste Lokesh) '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Chat Prompt Template"
      ],
      "metadata": {
        "id": "LvwVjGtrvum4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chat_template = ChatPromptTemplate(\n",
        "    messages=[\n",
        "        (\"system\",\"you are a helpful {domain} expert\"),\n",
        "        (\"human\",\"explain the {topic} in simple terms\")\n",
        "    ]\n",
        ")\n",
        "\n",
        "prompt = chat_template.invoke({\"domain\":\"medical\",\"topic\":\"maleria\"})\n",
        "prompt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2z_7e8EsvsH4",
        "outputId": "0e21ade2-287d-4ccb-ea91-5fe29beeb922"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatPromptValue(messages=[SystemMessage(content='you are a helpful medical expert', additional_kwargs={}, response_metadata={}), HumanMessage(content='explain the maleria in simple terms', additional_kwargs={}, response_metadata={})])"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gemini_model.invoke(prompt).content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "id": "b7fCVSzswLVN",
        "outputId": "84400c8e-4854-44e4-b194-ff7adb5881d0"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Malaria is a serious disease caused by a tiny parasite that's spread to humans through the bite of infected mosquitoes.  Imagine these parasites as little invaders that get into your bloodstream.\\n\\nHere's a simplified breakdown:\\n\\n1. **The Bite:** An infected mosquito bites you, injecting the malaria parasite into your blood.\\n2. **Liver Attack:** The parasite travels to your liver and multiplies rapidly.  This stage is usually silent, meaning you don't feel sick yet.\\n3. **Red Blood Cell Invasion:** After multiplying in the liver, the parasites burst out and invade your red blood cells. This is where the real trouble begins.\\n4. **Symptoms Appear:**  The parasites multiply inside the red blood cells, eventually causing them to burst. This cycle of invasion and bursting causes the classic malaria symptoms:\\n    * **High fever:**  Your body is fighting the infection.\\n    * **Chills:**  Sudden feeling of cold, often with shivering.\\n    * **Sweats:**  As the fever breaks, you may sweat profusely.\\n    * **Headache:**  A common symptom of many illnesses, including malaria.\\n    * **Muscle aches:**  Similar to the flu.\\n    * **Tiredness/fatigue:**  Feeling very weak and exhausted.\\n    * **Nausea and vomiting:**  Your body's reaction to the infection.\\n\\n5. **Serious Complications:** If left untreated, malaria can cause severe complications like anemia (low red blood cell count), organ failure (especially kidneys and liver), and even death.\\n\\n**In short:** Mosquito bite → parasite to liver → parasite to blood → red blood cells burst → you get sick.\\n\\n**Important Note:**  Malaria is preventable and treatable. If you think you might have malaria, see a doctor immediately.  Early diagnosis and treatment are crucial for a full recovery.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chaining using LCEL"
      ],
      "metadata": {
        "id": "N9tMxvlRwS_3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ast import parse\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "# from langchain_core.chains import LLMChain\n",
        "parser = StrOutputParser()\n",
        "\n",
        "prompt = PromptTemplate(\n",
        "    template=\"can you give me a detail explaination of {topic}\",\n",
        "    input_variables=['topic']\n",
        ")"
      ],
      "metadata": {
        "id": "zyZaJ5MQwSrY"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain = prompt | gemini_model | parser\n",
        "chain.invoke({\"topic\":\"astrology\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "id": "kFQxxjR8wqvT",
        "outputId": "d829b9e0-c094-4c1b-bdd0-8f8ef3f4d402"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Astrology is a complex system of beliefs and practices that posits a relationship between the positions and movements of celestial objects (like planets, stars, and the Sun and Moon) and events that occur on Earth, including human affairs and personality traits.  It\\'s important to distinguish that while astronomy is a science that studies these celestial objects, astrology is *not* considered a science.  It lacks empirical evidence and its claims are not testable using the scientific method.\\n\\nHere\\'s a breakdown of key concepts in astrology:\\n\\n**Core Principles:**\\n\\n* **As Above, So Below:** This principle suggests a mirroring effect between the macrocosm (the universe) and the microcosm (human beings).  Celestial events are believed to reflect or influence earthly events and vice versa.\\n* **Cycles and Patterns:** Astrology emphasizes the cyclical nature of time and the recurring patterns in planetary movements. These cycles are thought to influence human experiences and destinies.\\n* **Interconnectedness:**  Astrology views everything in the universe as interconnected and interdependent. The positions of celestial bodies are seen as part of a larger web of influence.\\n\\n**Key Elements of an Astrological Chart (Natal Chart/Birth Chart):**\\n\\n* **Planets:**  Represent different energies or archetypes within us and influence various aspects of our lives.  For example, the Sun represents our core identity, the Moon our emotions, Mercury our communication style, Venus our values and relationships, Mars our drive and energy, Jupiter our expansion and luck, Saturn our limitations and discipline, Uranus our innovation and change, Neptune our dreams and illusions, and Pluto our transformation and power.\\n* **Zodiac Signs:** The twelve signs (Aries, Taurus, Gemini, Cancer, Leo, Virgo, Libra, Scorpio, Sagittarius, Capricorn, Aquarius, and Pisces) represent different personality traits and archetypes.  The Sun\\'s position at the time of birth determines your \"Sun sign.\"\\n* **Houses:**  The astrological chart is divided into twelve houses, each representing a specific area of life, such as career, relationships, finances, and health. The planets\\' positions within these houses indicate their influence on those areas.\\n* **Aspects:**  Aspects refer to the angular relationships between planets in the chart.  These angles (e.g., conjunction, opposition, square, trine, sextile) are believed to modify the planets\\' energies and create either harmonious or challenging influences.\\n\\n**Different Branches of Astrology:**\\n\\n* **Natal Astrology:** Focuses on the individual\\'s birth chart to understand their personality, potential, and life path.\\n* **Predictive Astrology (Transit & Progression):**  Attempts to forecast future events by analyzing the current positions of planets in relation to the natal chart.  This includes techniques like transits (current planetary movements) and progressions (symbolic movement of chart factors).\\n* **Horary Astrology:**  Answers specific questions by casting a chart for the exact moment the question is asked.\\n* **Electional Astrology:**  Chooses auspicious times for important events, such as weddings or business ventures.\\n* **Mundane Astrology:**  Studies world events and historical cycles based on planetary movements.\\n* **Relationship Astrology (Synastry & Composite Charts):**  Compares the charts of two individuals to analyze their compatibility and relationship dynamics.\\n\\n**Criticisms of Astrology:**\\n\\n* **Lack of Scientific Evidence:**  There is no scientific evidence to support the claims made by astrology.  Studies have consistently failed to demonstrate any correlation between astrological predictions and actual outcomes.\\n* **The Barnum Effect:**  Many astrological readings rely on generalized statements that could apply to almost anyone. This phenomenon, known as the Barnum Effect, makes people believe that the readings are personalized and accurate when they are not.\\n* **Confirmation Bias:** People tend to remember instances that confirm their beliefs and ignore those that contradict them. This can lead to a false sense of validation for astrological predictions.\\n\\n**In Conclusion:**\\n\\nAstrology offers a rich and complex system for understanding ourselves and the world around us. While it lacks scientific validity, it continues to be a source of fascination and meaning for many people.  It\\'s crucial to approach astrology with critical thinking and to avoid making important life decisions solely based on astrological interpretations.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chain.get_graph().print_ascii()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0M82gBTUzqem",
        "outputId": "fb25d3af-695f-412a-87da-71658aa04818"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      +-------------+      \n",
            "      | PromptInput |      \n",
            "      +-------------+      \n",
            "             *             \n",
            "             *             \n",
            "             *             \n",
            "    +----------------+     \n",
            "    | PromptTemplate |     \n",
            "    +----------------+     \n",
            "             *             \n",
            "             *             \n",
            "             *             \n",
            "+------------------------+ \n",
            "| ChatGoogleGenerativeAI | \n",
            "+------------------------+ \n",
            "             *             \n",
            "             *             \n",
            "             *             \n",
            "    +-----------------+    \n",
            "    | StrOutputParser |    \n",
            "    +-----------------+    \n",
            "             *             \n",
            "             *             \n",
            "             *             \n",
            "+-----------------------+  \n",
            "| StrOutputParserOutput |  \n",
            "+-----------------------+  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sequential llm chain"
      ],
      "metadata": {
        "id": "uCVbZqzizrld"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt1=PromptTemplate(\n",
        "    template=\"analysis the the given text carefully {text} and take the necessary data\",\n",
        "    input_variables=[\"text\"]\n",
        ")\n",
        "\n",
        "prompt2=PromptTemplate(\n",
        "    template=\"summarize the given text in 2 bullet points {text}\",\n",
        "    input_variables=[\"text\"]\n",
        ")\n",
        "\n",
        "text=\"\"\"In November 2023, xAI began previewing Grok as a chatbot to selected people,[10] with participation in the early access program being limited to paid X Premium users.[11]\n",
        "\n",
        "It was announced that once the bot was out of early beta, it would only be available to higher tier X Premium+ subscribers.[12]\n",
        "\n",
        "At the time of the preview, xAI described the chatbot as \"a very early beta product – the best we could do with 2 months of training\" that could \"improve rapidly with each passing week\".[13]\n",
        "\n",
        "On March 11, 2024, Musk posted on X that the language model would go open source within a week. Six days later, on March 17, Grok-1 was open sourced under the Apache-2.0 license.[14][15] Disclosed were the networks architecture and its weight parameters.[16]\n",
        "\n",
        "On March 26, 2024, Musk announced that Grok would be enabled for premium subscribers, not just those on the higher-end tier, Premium+.[17]\n",
        "\n",
        "Grok-1.5\n",
        "Grok-1.5\n",
        "Developer(s)\txAI\n",
        "Initial release\tMay 15, 2024; 10 months ago\n",
        "Predecessor\tGrok-1.5\n",
        "Successor\tGrok-2\n",
        "Type\n",
        "Large language model\n",
        "Foundation model\n",
        "License\tProprietary\n",
        "Website\tx.ai/blog/grok-1.5\n",
        "On March 29, 2024, Grok-1.5 was announced, with \"improved reasoning capabilities\" and a context length of 128,000 tokens.[18] Grok-1.5 was released to all X Premium users on May 15, 2024.[1]\n",
        "\n",
        "On April 4, 2024, an update to X's \"Explore\" page included summaries of breaking news stories written by Grok, a task previously assigned to a human curation team.[19]\n",
        "\n",
        "On April 12, 2024, Grok-1.5 Vision (Grok-1.5V) was announced. Grok-1.5V is able to process a wide variety of visual information, including documents, diagrams, graphs, screenshots, and photographs.[20] Grok-1.5V was never released to the public.\n",
        "\n",
        "On May 4, 2024, Grok became available in the United Kingdom,[21] that being the only country in Europe to support Grok at the moment due to the impending Artificial Intelligence Act rules in the European Union. Grok was later reviewed by the EU and was released on May 16, 2024.[22]\"\"\"\n",
        "\n"
      ],
      "metadata": {
        "id": "Mcqxap1gzuCY"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain = prompt1 | gemini_model | parser | prompt2 | gemini_model | parser\n",
        "chain.get_graph().print_ascii()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sKUlEqCR0H1w",
        "outputId": "dccccdc5-5424-4516-d3b0-ed84430a557d"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      +-------------+      \n",
            "      | PromptInput |      \n",
            "      +-------------+      \n",
            "             *             \n",
            "             *             \n",
            "             *             \n",
            "    +----------------+     \n",
            "    | PromptTemplate |     \n",
            "    +----------------+     \n",
            "             *             \n",
            "             *             \n",
            "             *             \n",
            "+------------------------+ \n",
            "| ChatGoogleGenerativeAI | \n",
            "+------------------------+ \n",
            "             *             \n",
            "             *             \n",
            "             *             \n",
            "    +-----------------+    \n",
            "    | StrOutputParser |    \n",
            "    +-----------------+    \n",
            "             *             \n",
            "             *             \n",
            "             *             \n",
            "+-----------------------+  \n",
            "| StrOutputParserOutput |  \n",
            "+-----------------------+  \n",
            "             *             \n",
            "             *             \n",
            "             *             \n",
            "    +----------------+     \n",
            "    | PromptTemplate |     \n",
            "    +----------------+     \n",
            "             *             \n",
            "             *             \n",
            "             *             \n",
            "+------------------------+ \n",
            "| ChatGoogleGenerativeAI | \n",
            "+------------------------+ \n",
            "             *             \n",
            "             *             \n",
            "             *             \n",
            "    +-----------------+    \n",
            "    | StrOutputParser |    \n",
            "    +-----------------+    \n",
            "             *             \n",
            "             *             \n",
            "             *             \n",
            "+-----------------------+  \n",
            "| StrOutputParserOutput |  \n",
            "+-----------------------+  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = chain.invoke({\"text\":text})\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qmx9vm6V0RAK",
        "outputId": "91eef599-d016-457e-8575-658c859e5ad8"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "* xAI's Grok chatbot progressed rapidly from initial beta release in November 2023 to an expanded international release by May 2024, with key developments including open-sourcing Grok-1 and integrating it into X's platform.\n",
            "* Grok's development emphasized tight integration with X (formerly Twitter), particularly its Premium subscription service, and focused on rapid iteration with improved versions like Grok-1.5 offering enhanced reasoning and context length.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Parallel chain"
      ],
      "metadata": {
        "id": "6mEEdrqp0rJW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt1=PromptTemplate(\n",
        "    template=\"generate simple summary from the following text \\n {text}\",\n",
        "    input_variables=[\"text\"]\n",
        ")\n",
        "\n",
        "prompt2=PromptTemplate(\n",
        "    template=\"generate 3 question and answer from the following text \\n {text}\",\n",
        "    input_variables=[\"text\"]\n",
        "    )\n",
        "\n",
        "prompt3=PromptTemplate(\n",
        "    template=\"analysis the summary and qa and generate the 5 important quiz with 4 possible answer \\n summary: {summary}, Q&A: {qa}\",\n",
        "    input_variables=[\"summary\",\"qa\"]\n",
        ")"
      ],
      "metadata": {
        "id": "qjTGXV8d0tOE"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.schema.runnable import RunnableParallel\n",
        "\n",
        "parallel_chain = RunnableParallel(\n",
        "    summary=prompt1 | groq_model | parser,\n",
        "    qa=prompt2 | groq_model | parser\n",
        ")\n",
        "\n",
        "parallel_chain"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aCRFLUG-0yII",
        "outputId": "a9756326-f693-483e-d9d4-f7501d986b52"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{\n",
              "  summary: PromptTemplate(input_variables=['text'], input_types={}, partial_variables={}, template='generate simple summary from the following text \\n {text}')\n",
              "           | ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x7eaee0763710>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x7eaeeb1d4190>, model_name='deepseek-r1-distill-llama-70b', model_kwargs={}, groq_api_key=SecretStr('**********'))\n",
              "           | StrOutputParser(),\n",
              "  qa: PromptTemplate(input_variables=['text'], input_types={}, partial_variables={}, template='generate 3 question and answer from the following text \\n {text}')\n",
              "      | ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x7eaee0763710>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x7eaeeb1d4190>, model_name='deepseek-r1-distill-llama-70b', model_kwargs={}, groq_api_key=SecretStr('**********'))\n",
              "      | StrOutputParser()\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "parallel_chain.invoke({\"text\":text})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PokgHwZ51CK5",
        "outputId": "10581771-954a-4ae5-9599-8d945e066361"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'summary': \"<think>\\nOkay, I need to help the user by generating a simple summary from the provided text. Let me read through the text carefully to understand the key points.\\n\\nFirst, I see that the text is about xAI's Grok chatbot. It starts in November 2023 with a preview for paid X Premium users. So, that's the initial release phase.\\n\\nThen, there's a mention that after the early beta, only Premium+ subscribers would have access. But later, on March 26, 2024, Musk announced that Grok would be enabled for all Premium subscribers, not just Premium+. That's an important change in accessibility.\\n\\nNext, the text talks about Grok-1 being open-sourced on March 17, 2024, under the Apache-2.0 license. That's a significant step because open-sourcing allows developers to access and modify the model.\\n\\nMoving on, Grok-1.5 was announced on March 29, 2024, with improved features like reasoning capabilities and a longer context length. It was released on May 15, 2024. There's also a Vision version, Grok-1.5V, which can process visual data but wasn't publicly released.\\n\\nThe text also mentions Grok being available in the UK on May 4, 2024, and later in the EU after a review. This shows the expansion efforts into different regions.\\n\\nI should organize these points chronologically. Start with the preview in November 2023, then the open-sourcing, the changes in subscription access, the release of Grok-1.5, the Vision version, and finally the expansion to the UK and EU.\\n\\nI need to keep the summary concise, highlighting the key events and updates without getting too detailed. Make sure to mention the important dates and the significance of each update, like improving capabilities and expanding availability.\\n\\nAlright, putting it all together in a clear and straightforward manner should give the user a good overview of Grok's development and releases.\\n</think>\\n\\nIn November 2023, xAI introduced Grok, a chatbot, as a preview for paid X Premium users. Initially, access was limited, but by March 26, 2024, it became available to all Premium subscribers. On March 17, 2024, Grok-1 was open-sourced under the Apache-2.0 license. Grok-1.5, announced on March 29, 2024, offered improved reasoning and a longer context length, and was released to Premium users on May 15, 2024. A vision-enabled version, Grok-1.5V, was also announced but not publicly released. Grok became available in the UK on May 4, 2024, and later in the EU after regulatory review.\",\n",
              " 'qa': \"<think>\\nOkay, so I need to generate three questions and answers based on the provided text about Grok. Let me read through the text carefully to understand the key points.\\n\\nFirst, I see that Grok was previewed in November 2023 to selected users who were paid X Premium subscribers. So that's a good point for a question about the initial preview.\\n\\nNext, the text mentions that Grok-1 was open-sourced on March 17, 2024, under the Apache-2.0 license, which is a significant event. That could be the basis for another question.\\n\\nThen, Grok-1.5 was released on May 15, 2024, with improved features like reasoning capabilities and a longer context length. This seems important and can be the third question.\\n\\nI should frame each question to target these specific events and ensure the answers are concise, pulling the exact details from the text. Let me make sure the answers are accurate and directly reference the information given without adding any extra details.\\n</think>\\n\\n**Questions and Answers:**\\n\\n1. **When was Grok first previewed, and who had access to it?**  \\n   - Grok was first previewed in November 2023, and access was limited to paid X Premium users.\\n\\n2. **When was Grok-1 open-sourced, and under what license?**  \\n   - Grok-1 was open-sourced on March 17, 2024, under the Apache-2.0 license.\\n\\n3. **What improvements were made in Grok-1.5, and when was it released?**  \\n   - Grok-1.5 was released on May 15, 2024, with improved reasoning capabilities and a context length of 128,000 tokens.\"}"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chain = parallel_chain | prompt3 | groq_model | parser\n",
        "chain.invoke({\"text\":text})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "id": "gxQqAGJP1GvI",
        "outputId": "76ea5771-da88-474a-dc77-b27b0c914112"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"<think>\\nAlright, let's tackle this step by step. I need to create five important quiz questions with four possible answers each based on the provided summary and Q&A. First, I'll review the key points from the text to identify the most critical information.\\n\\n1. **Development and Release Timeline**: Grok was first previewed in November 2023 for paid X Premium users. In March 2024, it was open-sourced, and later that month, it became available to all X Premium subscribers, not just Premium+. Grok-1.5 was released on May 15, 2024, with enhanced features. Grok-1.5V was announced but not released publicly. Grok became available in the UK on May 4, 2024, and in the EU on May 16 after regulatory review.\\n\\n2. **Features and Updates**: Grok-1.5 introduced improved reasoning and a longer context length of 128,000 tokens. Grok also began generating news summaries in April, replacing human curators.\\n\\n3. **Availability and Expansion**: Initially limited to paid users, Grok expanded to all X Premium users in March 2024. It was released in the UK and EU later, with the EU requiring a regulatory review.\\n\\nNow, I'll identify the key pieces of information that would make good quiz questions. These should test knowledge of dates, features, availability, and specific versions.\\n\\n1. **First Preview Date and Audience**: When was Grok first previewed, and who was it available to?\\n2. **Open-Sourcing Announcement**: Who announced that Grok would be open-sourced, and when was it released under the Apache-2.0 license?\\n3. **Grok-1.5 Release Details**: What improvements were made in Grok-1.5, and when was it released to X Premium users?\\n4. **Grok Availability in the UK and EU**: When did Grok become available in the UK and the EU?\\n5. **Grok-1.5V Announcement**: What version of Grok was announced but not released publicly, and what feature did it include?\\n\\nFor each question, I'll create four possible answers, including the correct one and plausible distractors. I'll ensure the questions are clear and the answers are concise.\\n\\nLet me draft the questions and answers now, making sure to cover all the identified key points.\\n</think>\\n\\n**Quiz Questions:**\\n\\n**1. When was Grok first previewed, and who was it available to?**\\n   - A. November 2023, paid X Premium users  \\n   - B. March 2024, all X Premium users  \\n   - C. May 2024, free users  \\n   - D. April 2024, Premium+ subscribers  \\n\\n**Answer:** A. November 2023, paid X Premium users  \\n\\n---\\n\\n**2. Who announced that Grok would be open-sourced, and when was it released under the Apache-2.0 license?**  \\n   - A. Elon Musk, March 17, 2024  \\n   - B. xAI team, November 2023  \\n   - C. OpenAI, May 2024  \\n   - D. EU regulators, May 16, 2024  \\n\\n**Answer:** A. Elon Musk, March 17, 2024  \\n\\n---\\n\\n**3. What improvements were made in Grok-1.5, and when was it released to X Premium users?**  \\n   - A. Improved reasoning and context length of 128,000 tokens, released May 15, 2024  \\n   - B. Visual processing, released April 2024  \\n   - C. Language translation, released March 2024  \\n   - D. Text summarization, released November 2023  \\n\\n**Answer:** A. Improved reasoning and context length of 128,000 tokens, released May 15, 2024  \\n\\n---\\n\\n**4. When did Grok become available in the UK and the EU?**  \\n   - A. UK: May 4, 2024; EU: May 16, 2024  \\n   - B. UK: March 2024; EU: April 2024  \\n   - C. UK: November 2023; EU: March 2024  \\n   - D. UK: May 16, 2024; EU: May 4, 2024  \\n\\n**Answer:** A. UK: May 4, 2024; EU: May 16, 2024  \\n\\n---\\n\\n**5. What version of Grok was announced but not released publicly, and what feature did it include?**  \\n   - A. Grok-1.5V, visual data processing  \\n   - B. Grok-1.0, improved reasoning  \\n   - C. Grok-2.0, language translation  \\n   - D. Grok-1.5, text summarization  \\n\\n**Answer:** A. Grok-1.5V, visual data processing\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chain.get_graph().print_ascii()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WwtCUn7X1kOK",
        "outputId": "58042ca5-acf4-4ab1-f2cd-ec758291e940"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          +---------------------------+            \n",
            "          | Parallel<summary,qa>Input |            \n",
            "          +---------------------------+            \n",
            "                ***             ***                \n",
            "              **                   **              \n",
            "            **                       **            \n",
            "+----------------+              +----------------+ \n",
            "| PromptTemplate |              | PromptTemplate | \n",
            "+----------------+              +----------------+ \n",
            "          *                             *          \n",
            "          *                             *          \n",
            "          *                             *          \n",
            "    +----------+                  +----------+     \n",
            "    | ChatGroq |                  | ChatGroq |     \n",
            "    +----------+                  +----------+     \n",
            "          *                             *          \n",
            "          *                             *          \n",
            "          *                             *          \n",
            "+-----------------+            +-----------------+ \n",
            "| StrOutputParser |            | StrOutputParser | \n",
            "+-----------------+            +-----------------+ \n",
            "                ***             ***                \n",
            "                   **         **                   \n",
            "                     **     **                     \n",
            "          +----------------------------+           \n",
            "          | Parallel<summary,qa>Output |           \n",
            "          +----------------------------+           \n",
            "                         *                         \n",
            "                         *                         \n",
            "                         *                         \n",
            "                +----------------+                 \n",
            "                | PromptTemplate |                 \n",
            "                +----------------+                 \n",
            "                         *                         \n",
            "                         *                         \n",
            "                         *                         \n",
            "                   +----------+                    \n",
            "                   | ChatGroq |                    \n",
            "                   +----------+                    \n",
            "                         *                         \n",
            "                         *                         \n",
            "                         *                         \n",
            "                +-----------------+                \n",
            "                | StrOutputParser |                \n",
            "                +-----------------+                \n",
            "                         *                         \n",
            "                         *                         \n",
            "                         *                         \n",
            "            +-----------------------+              \n",
            "            | StrOutputParserOutput |              \n",
            "            +-----------------------+              \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text=\"\"\"AI agent or simply agent), expands this concept by proactively pursuing goals, making decisions, and taking actions over extended periods, thereby exemplifying a novel form of digital agency.[1]\n",
        "\n",
        "Intelligent agents can range from simple to highly complex. A basic thermostat or control system is considered an intelligent agent, as is a human being, or any other system that meets the same criteria—such as a firm, a state, or a biome.[2]\n",
        "\n",
        "Intelligent agents operate based on an objective function, which encapsulates their goals. They are designed to create and execute plans that maximize the expected value of this function upon completion.[3] For example, a reinforcement learning agent has a reward function, which allows programmers to shape its desired behavior.[4] Similarly, an evolutionary algorithm's behavior is guided by a fitness function.[5]\n",
        "\n",
        "Intelligent agents in artificial intelligence are closely related to agents in economics, and versions of the intelligent agent paradigm are studied in cognitive science, ethics, and the philosophy of practical reason, as well as in many interdisciplinary socio-cognitive modeling and computer social simulations.\n",
        "\n",
        "Intelligent agents are often described schematically as abstract functional systems similar to computer programs. To distinguish theoretical models from real-world implementations, abstract descriptions of intelligent agents are called abstract intelligent agents. Intelligent agents are also closely related to software agents—autonomous computer programs that carry out tasks on behalf of users. They are also referred to using a term borrowed from economics: a \"rational agent\".[2]\"\"\"\n",
        "\n",
        "\n",
        "result=chain.invoke({\"text\":text})\n",
        "\n",
        "\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4dUOxMPs1rsx",
        "outputId": "92361017-5d3b-478f-d0d1-a25fd0040697"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<think>\n",
            "Alright, I need to create five important quiz questions based on the provided summary and Q&A about intelligent agents. Each question should have four possible answers, including the correct one. Let me go through the summary and Q&A to identify key points that can be turned into questions.\n",
            "\n",
            "1. **Definition of an Intelligent Agent**: The summary explains that an intelligent agent is proactive, pursuing goals and making decisions over time. This could be a good question about the key characteristic.\n",
            "\n",
            "2. **Examples of Intelligent Agents**: The text mentions examples ranging from simple (thermostat) to complex (human, firm). A question about examples would be useful.\n",
            "\n",
            "3. **Objective Function in Intelligent Agents**: The summary describes how agents operate using an objective function, with examples like reward functions in reinforcement learning. This is a crucial concept for a question.\n",
            "\n",
            "4. **Relation to Other Fields**: The text connects intelligent agents to economics, cognitive science, and other disciplines. A question about interdisciplinary connections would be appropriate.\n",
            "\n",
            "5. **Terminology**: The summary mentions terms like \"software agents\" and \"rational agents.\" A question about terminology could test understanding of related concepts.\n",
            "\n",
            "Now, I'll formulate each question and provide four possible answers, ensuring one is correct based on the summary.\n",
            "\n",
            "For the first question, I'll ask about the defining feature. The correct answer is being proactive, using examples from the text.\n",
            "\n",
            "The second question will focus on examples, listing both simple and complex ones.\n",
            "\n",
            "The third question will target the objective function, mentioning reinforcement learning as an example.\n",
            "\n",
            "The fourth question will explore the interdisciplinary aspect, listing relevant fields.\n",
            "\n",
            "The fifth question will address the term \"rational agent\" and its origin.\n",
            "\n",
            "I need to ensure that the questions are clear and the answers are accurate. Each question should have one correct answer and three plausible distractors to test comprehension effectively.\n",
            "</think>\n",
            "\n",
            "**Quiz: Understanding Intelligent Agents**\n",
            "\n",
            "**1. What is a defining characteristic of an intelligent agent?**  \n",
            "a) Reacting only to immediate stimuli  \n",
            "b) Being proactive in pursuing goals and making decisions over time  \n",
            "c) Operating solely based on pre-programmed rules without adaptability  \n",
            "d) Functioning only in physical environments  \n",
            "\n",
            "**Correct Answer:** b) Being proactive in pursuing goals and making decisions over time  \n",
            "\n",
            "---\n",
            "\n",
            "**2. Which of the following is an example of an intelligent agent?**  \n",
            "a) A manual calculator  \n",
            "b) A thermostat  \n",
            "c) A human being  \n",
            "d) Both b and c  \n",
            "\n",
            "**Correct Answer:** d) Both b and c  \n",
            "\n",
            "---\n",
            "\n",
            "**3. What is the primary function that guides the behavior of intelligent agents?**  \n",
            "a) Reward function  \n",
            "b) Punishment function  \n",
            "c) Objective function  \n",
            "d) Survival function  \n",
            "\n",
            "**Correct Answer:** c) Objective function  \n",
            "\n",
            "---\n",
            "\n",
            "**4. Intelligent agents are studied in which of the following fields?**  \n",
            "a) Economics  \n",
            "b) Cognitive science  \n",
            "c) Ethics  \n",
            "d) All of the above  \n",
            "\n",
            "**Correct Answer:** d) All of the above  \n",
            "\n",
            "---\n",
            "\n",
            "**5. What term from economics is also used to refer to intelligent agents?**  \n",
            "a) Rational agent  \n",
            "b) Economic agent  \n",
            "c) Cognitive agent  \n",
            "d) Ethical agent  \n",
            "\n",
            "**Correct Answer:** a) Rational agent  \n",
            "\n",
            "---\n",
            "\n",
            "This quiz effectively tests the understanding of key concepts related to intelligent agents, covering their definition, examples, guiding functions, interdisciplinary relevance, and terminology.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## JSON Ouput parser"
      ],
      "metadata": {
        "id": "4fyyIv3r2-SS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.output_parsers import JsonOutputParser\n",
        "\n",
        "json_parser = JsonOutputParser()\n",
        "json_parser.get_format_instructions()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "yw3IriPv3BOb",
        "outputId": "1b0187e8-a641-47cf-ed2e-5fd68500077c"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Return a JSON object.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "template=PromptTemplate(\n",
        "    template=\"give me name, age and city from the provided text {text} \\n {format_instructions}\" ,\n",
        "    input_variables=['text'],\n",
        "    partial_variables={\"format_instructions\":json_parser.get_format_instructions()}\n",
        ")\n",
        "\n",
        "text=\"\"\"hi my name is Lokesh Parab my age is 25 and i am belong to mumbai\"\"\"\n",
        "\n",
        "prompt=template.format(text=text)\n",
        "prompt\n",
        "\n",
        "\n",
        "result=groq_model.invoke(prompt)\n",
        "result\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C1bXxBvO3UVG",
        "outputId": "dc05eef6-bda9-4763-b87a-e710b39649a7"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='<think>\\nOkay, the user has given me a query where they want me to extract specific information from a provided text and return it as a JSON object. Let me break this down step by step.\\n\\nFirst, I read the query: \"hi my name is Lokesh Parab my age is 25 and i am belong to mumbai. Return a JSON object.\" So, the user wants a JSON with name, age, and city.\\n\\nI notice that the text isn\\'t in the standard format, but I can still parse it. The name is \"Lokesh Parab,\" which I should include as a single string. The age is 25, so that\\'s straightforward. For the city, the text says \"mumbai,\" but I should probably capitalize it to \"Mumbai\" for consistency.\\n\\nNow, I need to structure this into a JSON object. I\\'ll make sure the keys are \"name,\" \"age,\" and \"city,\" each mapped to their respective values. I\\'ll double-check the spelling and capitalization to ensure accuracy.\\n\\nI also consider the user\\'s intent. They might be testing how well I can parse text and format JSON. So, precision is key here. I should avoid any markdown in the response, just plain JSON.\\n\\nFinally, I\\'ll present the JSON clearly, making sure it\\'s valid and easy to read. That should meet the user\\'s requirements effectively.\\n</think>\\n\\nHere is the extracted information in JSON format:\\n\\n```json\\n{\\n  \"name\": \"Lokesh Parab\",\\n  \"age\": 25,\\n  \"city\": \"Mumbai\"\\n}\\n```', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 326, 'prompt_tokens': 40, 'total_tokens': 366, 'completion_time': 1.185454545, 'prompt_time': 0.006210504, 'queue_time': 0.422810375, 'total_time': 1.191665049}, 'model_name': 'deepseek-r1-distill-llama-70b', 'system_fingerprint': 'fp_454c494f52', 'finish_reason': 'stop', 'logprobs': None}, id='run-1aa485d4-240d-4749-bb03-7d417078412a-0', usage_metadata={'input_tokens': 40, 'output_tokens': 326, 'total_tokens': 366})"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result=json_parser.parse(result.content)\n",
        "result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a4ADiBO54OJN",
        "outputId": "cd29d2e6-1391-4b8c-9d55-2c21979ca83d"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'name': 'Lokesh Parab', 'age': 25, 'city': 'Mumbai'}"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chain = template | groq_model | json_parser\n",
        "chain.invoke({\"text\":text})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l1GPHxVP4c97",
        "outputId": "6fc6c8e4-ba18-413a-8cc6-0f0f758a557d"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'name': 'Lokesh Parab', 'age': 25, 'city': 'Mumbai'}"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create Chatbot"
      ],
      "metadata": {
        "id": "x5SUJtlodABz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chat_history = [\n",
        "    SystemMessage(\n",
        "       \"you are a helpful assistant\"\n",
        "    )\n",
        "]\n",
        "\n",
        "model_name = \"openai\" # @param [\"openai\",\"googleai\",\"claudeai\",\"groqai\"]\n",
        "\n",
        "# def get_model(model_name):\n",
        "#   if model_name==\"openai\":\n",
        "#     return ChatOpenAI(\"gpt-4o-mini\")\n",
        "#   elif model_name==\"googleai\":\n",
        "#     return ChatGoogleGenerativeAI(model='gemini-1.5-pro')\n",
        "#   elif model_name==\"claudeai\":\n",
        "#     return ChatAnthropic(model=\"claude-2\")\n",
        "#   elif model_name==\"groqai\":\n",
        "#     return ChatGroq(model=\"deepseek-r1-distill-llama-70b\")\n",
        "get_model={\n",
        "    \"openai\":ChatOpenAI(model=\"gpt-4o-mini\"),\n",
        "    \"googleai\":ChatGoogleGenerativeAI(model='gemini-1.5-pro'),\n",
        "    \"claudeai\":ChatAnthropic(model=\"claude-2\"),\n",
        "    \"groqai\":ChatGroq(model=\"deepseek-r1-distill-llama-70b\")\n",
        "}\n",
        "\n",
        "chat_model = get_model[model_name]\n",
        "\n",
        "while True:\n",
        "  user_input = input(\"User_input:\")\n",
        "\n",
        "  chat_history.append(HumanMessage(content=user_input))\n",
        "  if user_input==\"exit\":\n",
        "        break\n",
        "  response = chat_model.invoke(chat_history)\n",
        "  chat_history.append(AIMessage(content=response.content))\n",
        "  print(\"AI Generated Answer:\",response.content)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HV9ATnL8c2Jf",
        "outputId": "43fb0431-a6f8-491c-f5a2-4fb05be3c38b"
      },
      "execution_count": 46,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "User_input:What is capital of India\n",
            "AI Generated Answer: The capital of India is New Delhi.\n",
            "User_input:Who is prime minister of India\n",
            "AI Generated Answer: As of my last knowledge update in October 2023, the Prime Minister of India is Narendra Modi. He has been in office since May 26, 2014. Please verify with up-to-date sources to ensure this information is current.\n",
            "User_input:What is age of Narendra Modi\n",
            "AI Generated Answer: Narendra Modi was born on September 17, 1950. As of today, October 4, 2023, he is 73 years old.\n",
            "User_input:Today is 28 April 2025\n",
            "AI Generated Answer: Thank you for the update! If today is April 28, 2025, then Narendra Modi, born on September 17, 1950, would be 74 years old and will turn 75 later this year.\n",
            "User_input:exit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "93yBSJeXzfKX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
